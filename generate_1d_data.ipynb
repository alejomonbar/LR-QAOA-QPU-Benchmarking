{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288a463e",
   "metadata": {},
   "source": [
    "# Generate 1D Chain JSON Data from Numpy Files\n",
    "\n",
    "This notebook extracts real experimental data from numpy files and creates a JSON file for the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7278484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4130a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5-qubit data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {\"5q\": {}, \"100q\": {}}\n",
    "nq = 5\n",
    "case = \"\"\n",
    "prop = \"r\"\n",
    "\n",
    "print(\"Processing 5-qubit data...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c67504c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  qasm_simulator: max_r = 1.0 at p = 50\n",
      "  iqm_emerald: max_r = 0.838 at p = 5\n",
      "  iqm_garnet: max_r = 0.831 at p = 5\n",
      "  ibm_fez: max_r = 0.868 at p = 9\n",
      "  ibm_marrakesh: max_r = 0.923 at p = 15\n",
      "  ibm_brisbane: max_r = 0.843 at p = 5\n",
      "  rigetti_ankaa_2: max_r = 0.608 at p = 3\n",
      "  rigetti_ankaa_3: max_r = 0.604 at p = 3\n"
     ]
    }
   ],
   "source": [
    "# Define backends for 5q\n",
    "backends_5q = [\"qasm_simulator\", \"iqm_emerald\", \"iqm_garnet\", \"ibm_fez\", \n",
    "               \"ibm_marrakesh\", \"ibm_brisbane\", \"rigetti_ankaa_2\", \"rigetti_ankaa_3\"]\n",
    "\n",
    "for backend in backends_5q:\n",
    "    try:\n",
    "        results = np.load(f\"./Data/{backend}/{nq}_1D.npy\", allow_pickle=True).item()\n",
    "        \n",
    "        # Override iqm_emerald with AWS version\n",
    "        if backend == \"iqm_emerald\":\n",
    "            results = np.load(f\"./Data/iqm_emerald/{nq}_1D_aws.npy\", allow_pickle=True).item()\n",
    "        \n",
    "        delta = results[\"Deltas\"][0]\n",
    "        ps = results[\"ps\"]\n",
    "        \n",
    "        # Find best section based on highest mean\n",
    "        best_mean = 0\n",
    "        best_sec = None\n",
    "        for sec_i in results[f\"postprocessing{case}\"][delta][ps[0]].keys():\n",
    "            res_i = [results[f\"postprocessing{case}\"][delta][p][sec_i][prop] for p in ps]\n",
    "            if np.mean(res_i) > best_mean:\n",
    "                best_sec = res_i\n",
    "                best_mean = np.mean(res_i)\n",
    "        \n",
    "        # Extract random baseline\n",
    "        random_r = results.get(f\"random{case}\", {}).get(prop, 0.667)\n",
    "        \n",
    "        data[\"5q\"][backend] = {\n",
    "            \"qubits\": nq,\n",
    "            \"p_values\": ps,\n",
    "            \"r_values\": [round(r, 3) for r in best_sec],\n",
    "            \"max_r\": round(max(best_sec), 3),\n",
    "            \"optimal_p\": int(ps[np.argmax(best_sec)]),\n",
    "            \"random_r\": round(random_r, 3)\n",
    "        }\n",
    "        print(f\"  {backend}: max_r = {round(max(best_sec), 3)} at p = {ps[np.argmax(best_sec)]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not load {backend}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0968f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  originq_wukong: max_r = 0.832 at p = 4\n",
      "  iqm_sirius: max_r = 0.685 at p = 3\n"
     ]
    }
   ],
   "source": [
    "# Add special cases for 5q\n",
    "try:\n",
    "    results = np.load(f\"./Data/originq_wukong/{nq}_1D_2.npy\", allow_pickle=True).item()\n",
    "    delta = results[\"Deltas\"][0]\n",
    "    ps = results[\"ps\"]\n",
    "    best_mean = 0\n",
    "    for sec_i in results[f\"postprocessing{case}\"][delta][ps[0]].keys():\n",
    "        res_i = [results[f\"postprocessing{case}\"][delta][p][sec_i][prop] for p in ps]\n",
    "        if np.mean(res_i) > best_mean:\n",
    "            best_sec = res_i\n",
    "            best_mean = np.mean(res_i)\n",
    "    \n",
    "    data[\"5q\"][\"originq_wukong\"] = {\n",
    "        \"qubits\": nq,\n",
    "        \"p_values\": ps,\n",
    "        \"r_values\": [round(r, 3) for r in best_sec],\n",
    "        \"max_r\": round(max(best_sec), 3),\n",
    "        \"optimal_p\": int(ps[np.argmax(best_sec)]),\n",
    "        \"random_r\": 0.667\n",
    "    }\n",
    "    print(f\"  originq_wukong: max_r = {round(max(best_sec), 3)} at p = {ps[np.argmax(best_sec)]}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Warning: Could not load originq_wukong: {e}\")\n",
    "\n",
    "try:\n",
    "    results = np.load(f\"./Data/iqm_sirius/{nq}_1D_Single.npy\", allow_pickle=True).item()\n",
    "    delta = results[\"Deltas\"][0]\n",
    "    ps = results[\"ps\"]\n",
    "    best_mean = 0\n",
    "    for sec_i in results[f\"postprocessing{case}\"][delta][ps[0]].keys():\n",
    "        res_i = [results[f\"postprocessing{case}\"][delta][p][sec_i][prop] for p in ps]\n",
    "        if np.mean(res_i) > best_mean:\n",
    "            best_sec = res_i\n",
    "            best_mean = np.mean(res_i)\n",
    "    \n",
    "    data[\"5q\"][\"iqm_sirius\"] = {\n",
    "        \"qubits\": nq,\n",
    "        \"p_values\": ps,\n",
    "        \"r_values\": [round(r, 3) for r in best_sec],\n",
    "        \"max_r\": round(max(best_sec), 3),\n",
    "        \"optimal_p\": int(ps[np.argmax(best_sec)]),\n",
    "        \"random_r\": 0.667\n",
    "    }\n",
    "    print(f\"  iqm_sirius: max_r = {round(max(best_sec), 3)} at p = {ps[np.argmax(best_sec)]}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Warning: Could not load iqm_sirius: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b6f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 100-qubit data...\n",
      "\n",
      "  ibm_marrakesh: max_r = 0.773 at p = 8\n",
      "  ibm_brisbane: max_r = 0.756 at p = 5\n",
      "  ibm_sherbrooke: max_r = 0.721 at p = 5\n",
      "  ibm_kyiv: max_r = 0.723 at p = 4\n",
      "  ibm_nazca: max_r = 0.673 at p = 5\n",
      "  ibm_kyoto: max_r = 0.662 at p = 4\n",
      "  ibm_osaka: max_r = 0.675 at p = 8\n",
      "  ibm_fez: max_r = 0.777 at p = 9\n",
      "  ibm_brussels: max_r = 0.719 at p = 5\n",
      "  ibm_strasbourg: max_r = 0.711 at p = 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing 100-qubit data...\\n\")\n",
    "nq = 100\n",
    "delta = 1\n",
    "kk = 0\n",
    "\n",
    "backends_100q = [\"ibm_marrakesh\", \"ibm_brisbane\", \"ibm_sherbrooke\", \"ibm_kyiv\", \n",
    "                 \"ibm_nazca\", \"ibm_kyoto\", \"ibm_osaka\", \"ibm_fez\", \"ibm_brussels\", \n",
    "                 \"ibm_strasbourg\"]\n",
    "\n",
    "for backend in backends_100q:\n",
    "    try:\n",
    "        results = np.load(f\"./Data/{backend}/{nq}_1D.npy\", allow_pickle=True).item()\n",
    "        res_backend = results[f\"postprocessing{case}\"]\n",
    "        ps = list(res_backend[delta].keys())\n",
    "        rs = [res_backend[delta][p][kk][prop] for p in ps]\n",
    "        \n",
    "        # Get random baseline\n",
    "        if backend == \"ibm_brisbane\":\n",
    "            random_r = results.get(f\"random{case}\", {}).get(prop, 0.50)\n",
    "        else:\n",
    "            random_r = 0.50\n",
    "        \n",
    "        data[\"100q\"][backend] = {\n",
    "            \"qubits\": nq,\n",
    "            \"p_values\": ps,\n",
    "            \"r_values\": [round(r, 3) for r in rs],\n",
    "            \"max_r\": round(max(rs), 3),\n",
    "            \"optimal_p\": int(ps[np.argmax(rs)]),\n",
    "            \"random_r\": round(random_r, 3)\n",
    "        }\n",
    "        print(f\"  {backend}: max_r = {round(max(rs), 3)} at p = {ps[np.argmax(rs)]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not load {backend}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada993fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ibm_torino-v1: max_r = 0.76 at p = 9\n",
      "  ibm_torino-v0: max_r = 0.728 at p = 9\n",
      "  ibm_boston: max_r = 0.841 at p = 10\n"
     ]
    }
   ],
   "source": [
    "# Add torino variants\n",
    "try:\n",
    "    results = np.load(f\"./Data/ibm_torino/{nq}_1D_v1.npy\", allow_pickle=True).item()\n",
    "    res_backend = results[f\"postprocessing{case}\"]\n",
    "    ps = list(res_backend[delta].keys())\n",
    "    rs = [res_backend[delta][p][kk][prop] for p in ps]\n",
    "    \n",
    "    data[\"100q\"][\"ibm_torino-v1\"] = {\n",
    "        \"qubits\": nq,\n",
    "        \"p_values\": ps,\n",
    "        \"r_values\": [round(r, 3) for r in rs],\n",
    "        \"max_r\": round(max(rs), 3),\n",
    "        \"optimal_p\": int(ps[np.argmax(rs)]),\n",
    "        \"random_r\": 0.50\n",
    "    }\n",
    "    print(f\"  ibm_torino-v1: max_r = {round(max(rs), 3)} at p = {ps[np.argmax(rs)]}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Warning: Could not load ibm_torino-v1: {e}\")\n",
    "\n",
    "try:\n",
    "    results = np.load(f\"./Data/ibm_torino/{nq}_1D.npy\", allow_pickle=True).item()\n",
    "    res_backend = results[f\"postprocessing{case}\"]\n",
    "    ps = list(res_backend[delta].keys())\n",
    "    rs = [res_backend[delta][p][kk][prop] for p in ps]\n",
    "    \n",
    "    data[\"100q\"][\"ibm_torino-v0\"] = {\n",
    "        \"qubits\": nq,\n",
    "        \"p_values\": ps,\n",
    "        \"r_values\": [round(r, 3) for r in rs],\n",
    "        \"max_r\": round(max(rs), 3),\n",
    "        \"optimal_p\": int(ps[np.argmax(rs)]),\n",
    "        \"random_r\": 0.50\n",
    "    }\n",
    "    print(f\"  ibm_torino-v0: max_r = {round(max(rs), 3)} at p = {ps[np.argmax(rs)]}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Warning: Could not load ibm_torino-v0: {e}\")\n",
    "\n",
    "try:\n",
    "    results = np.load(f\"./Data/ibm_boston/{nq}_1D.npy\", allow_pickle=True).item()\n",
    "    res_backend = results[f\"postprocessing{case}\"]\n",
    "    ps = list(res_backend[delta].keys())\n",
    "    rs = [res_backend[delta][p][kk][prop] for p in ps]\n",
    "    \n",
    "    data[\"100q\"][\"ibm_boston\"] = {\n",
    "        \"qubits\": nq,\n",
    "        \"p_values\": ps,\n",
    "        \"r_values\": [round(r, 3) for r in rs],\n",
    "        \"max_r\": round(max(rs), 3),\n",
    "        \"optimal_p\": int(ps[np.argmax(rs)]),\n",
    "        \"random_r\": 0.50\n",
    "    }\n",
    "    print(f\"  ibm_boston: max_r = {round(max(rs), 3)} at p = {ps[np.argmax(rs)]}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Warning: Could not load ibm_boston: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da74b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "output_path = Path(\"Data/1d_chain_processed.json\")\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Successfully saved data to {output_path}\")\n",
    "print(f\"  5q backends: {len(data['5q'])}\")\n",
    "print(f\"  100q backends: {len(data['100q'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
