{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qnexus as qnx\n",
    "import numpy as np\n",
    "\n",
    "qnx.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5faac398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qnexus as qnx\n",
    "import uuid\n",
    "\n",
    "unique_suffix = uuid.uuid1()\n",
    "\n",
    "project = qnx.projects.get_or_create(\"Helios-Samples\")\n",
    "qnx.context.set_active_project(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17024584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from guppylang import guppy\n",
    "from guppylang.defs import GuppyFunctionDefinition\n",
    "from guppylang.std.builtins import array, comptime, result\n",
    "from guppylang.std.quantum import rx, rz, cx, h, measure_array, qubit\n",
    "from guppylang.emulator import EmulatorResult\n",
    "from guppylang.std.angles import angle, pi\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76e47a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions from FC-Experiments.ipynb\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "def cost_maxcut(bitstring, weights):\n",
    "    \"\"\"\n",
    "    Computes the cost of a given bitstring solution for the Max-Cut problem.\n",
    "    \n",
    "    Parameters:\n",
    "    bitstring (str): A binary string representing a partition of the graph nodes.\n",
    "    weights (dict): A dictionary where keys are edge tuples (i, j) and values are edge weights.\n",
    "    \n",
    "    Returns:\n",
    "    float: The computed cost of the Max-Cut solution.\n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    for i, j in weights.keys():\n",
    "        if bitstring[i] + bitstring[j] in [\"10\", \"01\"]:\n",
    "            cost += weights[i, j]\n",
    "    return cost\n",
    "\n",
    "def objective_MaxCut(samples_dict, G, optimal):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a quantum algorithm for the Max-Cut problem.\n",
    "    \n",
    "    Parameters:\n",
    "    samples_dict (dict): A dictionary where keys are bitstrings, values are counts.\n",
    "    G (networkx.Graph): The input weighted graph.\n",
    "    optimal (str): The optimal bitstring solution.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Contains results, max_cut, approximation ratio r, and probability.\n",
    "    \"\"\"\n",
    "    weights = {(i, j): (G[i][j][\"weight\"] if len(G[i][j]) != 0 else 1) for i, j in G.edges}\n",
    "    max_cost = cost_maxcut(optimal, weights)\n",
    "    \n",
    "    results = []\n",
    "    probability = 0\n",
    "    \n",
    "    for bitstring, counts in samples_dict.items():\n",
    "        cost = cost_maxcut(bitstring, weights)\n",
    "        r = cost / max_cost\n",
    "        results.append([cost, r, counts])\n",
    "        \n",
    "        if abs(cost - max_cost) < 1e-6:\n",
    "            probability += counts\n",
    "        \n",
    "        if cost > max_cost:\n",
    "            print(f\"Found better solution than optimal: {cost - max_cost}\")\n",
    "    \n",
    "    results = np.array(results)\n",
    "    shots = np.sum(results[:, 2])\n",
    "    rT = np.sum(results[:, 0] * results[:, 2]) / (shots * max_cost)\n",
    "    probability /= shots\n",
    "    \n",
    "    return {\n",
    "        \"results\": np.array(results),\n",
    "        \"G\": G,\n",
    "        \"weights\": weights,\n",
    "        \"max_cut\": max_cost,\n",
    "        \"r\": rT,\n",
    "        \"probability\": probability\n",
    "    }\n",
    "\n",
    "def random_samples(num_samples, n_qubits):\n",
    "    \"\"\"\n",
    "    Generates random bitstring samples for a given number of qubits.\n",
    "\n",
    "    Parameters:\n",
    "    num_samples (int): The number of random bitstrings to generate.\n",
    "    n_qubits (int): The number of qubits (length of each bitstring).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are randomly generated bitstrings \n",
    "          and values are their occurrence counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    random_samples = defaultdict(int)  # Dictionary to store bitstrings and their counts\n",
    "\n",
    "    # Generate random bitstrings and count their occurrences\n",
    "    for _ in range(num_samples):\n",
    "        bitstring = \"\".join(str(i) for i in np.random.choice([0, 1], n_qubits))  # Generate a random bitstring\n",
    "        random_samples[bitstring] += 1  # Increment count for the generated bitstring\n",
    "\n",
    "    return random_samples  # Return the dictionary of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "126fb70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(shots: EmulatorResult) -> Counter[str]:\n",
    "    \"\"\"Counter treating all results from a shot as entries in a single bitstring\"\"\"\n",
    "    counter_list = []\n",
    "    for shot in shots:\n",
    "        for e in shot:\n",
    "            bitstring = \"\".join(str(k) for k in e[1])\n",
    "            counter_list.append(bitstring)\n",
    "\n",
    "    return dict(Counter(counter_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cf9cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaoa(graph: nx.Graph, betas:list, gammas:list) -> GuppyFunctionDefinition:\n",
    "    edges = list(graph.edges)\n",
    "    num_layers = len(gammas)\n",
    "    n_qb = graph.number_of_nodes()\n",
    "    max_weight = max([graph[i][j][\"weight\"] for i, j in graph.edges])\n",
    "    weights = [graph[i][j][\"weight\"]/max_weight for i, j in graph.edges]\n",
    "    pi_num = float(np.pi)\n",
    "    @guppy\n",
    "    def main() -> None:\n",
    "        qs = array(qubit() for _ in range(comptime(n_qb)))\n",
    "        for i in range(len(qs)):\n",
    "            h(qs[i])\n",
    "        for layer_i in range(comptime(num_layers)):\n",
    "            kk = 0\n",
    "            for i, j in comptime(edges):\n",
    "                cx(qs[i], qs[j])\n",
    "                rz(qs[j], angle(2.0 * comptime(gammas)[layer_i] * comptime(weights)[kk] / comptime(pi_num)))\n",
    "                cx(qs[i], qs[j])\n",
    "                kk += 1\n",
    "            for i in range(len(qs)):\n",
    "                rx(qs[i], angle(- 2.0 * comptime(betas)[layer_i] / comptime(pi_num)))\n",
    "        result(\"c\", measure_array(qs))\n",
    "\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3e8ec3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{3: np.float64(0.846844859813084), 4: np.float64(0.8489869158878508)}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_i = np.load(\"/Users/alejomonbar/Documents/GitHub/LR-QAOA-QPU-Benchmarking/Data/H2-1/50_FC.npy\", allow_pickle=True).item()\n",
    "print(res_i[\"Deltas\"][0])\n",
    "{p:res_i[\"postprocessing\"][res_i[\"Deltas\"][0]][p][0][\"r\"] for p in res_i[\"ps\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "789a59c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 100, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fa5473e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionary\n",
    "results = {}\n",
    "backend_name = \"quantinuum_helios_1e\"  # Backend name for saving results\n",
    "\n",
    "# Problem parameters\n",
    "nq = 98\n",
    "problems = np.load(\"./Data/WMC_FC.npy\", allow_pickle=True).item()\n",
    "graph = problems[nq][\"G\"]\n",
    "optimal_sol = problems[nq][\"sol\"]\n",
    "\n",
    "# QAOA parameters\n",
    "ps = [3]  # List of QAOA depths to test\n",
    "shots = 50\n",
    "\n",
    "# Store metadata in results\n",
    "deltas = [0.2]\n",
    "results[\"Deltas\"] = deltas  # Store as list of tuples\n",
    "results[\"G\"] = graph\n",
    "results[\"sections\"] = 1\n",
    "results[\"shots\"] = shots\n",
    "results[\"ps\"] = ps\n",
    "results[\"optimal\"] = optimal_sol\n",
    "results[\"total_qubits_used\"] = list(range(nq))\n",
    "\n",
    "# Test local emulator for small problems\n",
    "programs = []\n",
    "dict_results = []\n",
    "for delta in deltas:\n",
    "    for p in ps:\n",
    "        gammas = [k * delta / p for k in range(1, p + 1)]\n",
    "        betas = [(p - k + 1) * delta / p for k in range(1, p + 1)]\n",
    "        graph_prog = qaoa(graph, betas, gammas)\n",
    "        graph_prog_compiled = graph_prog.compile()\n",
    "        programs.append(graph_prog_compiled)\n",
    "\n",
    "        if nq <= 20:\n",
    "            res = graph_prog.emulator(n_qubits=nq).with_shots(shots).run()\n",
    "            samples = get_counts(res)\n",
    "            dict_results.append(samples)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nexus_programs = [qnx.hugr.upload(\n",
    "    graph_prog_compiled, \n",
    "    name=f\"qaoa-fc-{nq}q-{unique_suffix}\"\n",
    ") for graph_prog_compiled in programs]\n",
    "\n",
    "prediction = qnx.hugr.cost(\n",
    "    programs=nexus_programs, \n",
    "    n_shots=len(nexus_programs) * [shots]  # More shots for better statistics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e6f91b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = qnx.models.HeliosConfig(\n",
    "    system_name=\"Helios-1E\",\n",
    "    max_cost=np.ceil(prediction),\n",
    "    emulator_config=qnx.models.HeliosEmulatorConfig(\n",
    "        n_qubits=nq, \n",
    "        simulator=qnx.models.MatrixProductStateSimulator(chi=16)\n",
    "    )\n",
    ")\n",
    "\n",
    "result_ref = qnx.start_execute_job(\n",
    "    programs=nexus_programs,\n",
    "    n_shots= len(ps) * [shots],  # Match the cost prediction\n",
    "    backend_config=config,\n",
    "    name=f\"QAOA-FC-{nq}q-Helios-Emulator-{unique_suffix}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1cfb50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown OpType in BackendInfo: `%`, will omit from BackendInfo. Consider updating your pytket version.\n",
      "Unknown OpType in BackendInfo: `%`, will omit from BackendInfo. Consider updating your pytket version.\n",
      "Unknown OpType in BackendInfo: `%`, will omit from BackendInfo. Consider updating your pytket version.\n",
      "Unknown OpType in BackendInfo: `%`, will omit from BackendInfo. Consider updating your pytket version.\n"
     ]
    }
   ],
   "source": [
    "def get_dict_results(job_result):\n",
    "    # Process the results - extract bitstrings from QsysShot objects\n",
    "    outcomes = []\n",
    "    for shot_result in job_result:\n",
    "        # Quantinuum returns measurements in index order: shot_result[0] is q0, etc.\n",
    "        # Construct bitstring where bitstring[i] represents node i\n",
    "        bitstring = shot_result.to_register_bits()[\"c\"]\n",
    "        outcomes.append(bitstring)\n",
    "    samples_dict = dict(Counter(outcomes))\n",
    "    return samples_dict\n",
    "\n",
    "qnx.jobs.wait_for(result_ref)\n",
    "job_results = [qnx.jobs.results(result_ref)[i].download_result() for i in range(len(nexus_programs))]\n",
    "\n",
    "dict_results = [get_dict_results(job_result) for job_result in job_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "288533c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"samples\"] = {\n",
    "    delta: {\n",
    "        p: {k: v for k, v in dict_results[i + nd * len(ps)].items()}\n",
    "        for i, p in enumerate(results[\"ps\"])\n",
    "    }\n",
    "    for nd, delta in enumerate(results[\"Deltas\"])\n",
    "    }\n",
    "extra = \"\"\n",
    "# Save the results dictionary as a NumPy binary file for future use\n",
    "os.makedirs(f\"./Data/{backend_name}/\", exist_ok=True)\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC{extra}.npy\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7a961a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- p = 3 -------------\n"
     ]
    }
   ],
   "source": [
    "# Get the number of nodes (qubits) in the graph problem\n",
    "nq = results[\"G\"].number_of_nodes()\n",
    "\n",
    "# Get the number of sections (used for processing multiple groups of qubits in a single execution)\n",
    "sections = results[\"sections\"]\n",
    "\n",
    "# Initialize dictionaries to store postprocessing results\n",
    "postprocessing = {}\n",
    "postprocessing_mitig = {}\n",
    "\n",
    "# Iterate over different delta values (used for QAOA parameter tuning)\n",
    "for delta in results[\"samples\"]:\n",
    "    postprocessing[delta] = {}\n",
    "    postprocessing_mitig[delta] = {}\n",
    "\n",
    "    # Iterate over different QAOA depths (p values)\n",
    "    for p in results[\"samples\"][delta]:\n",
    "        print(f\"----------- p = {p} -------------\")\n",
    "        postprocessing[delta][p] = {}\n",
    "        postprocessing_mitig[delta][p] = {}\n",
    "\n",
    "        # Iterate over different sections (to handle multiple independent executions within a job)\n",
    "        for sec in range(sections):\n",
    "            samples_sec = defaultdict(int)\n",
    "\n",
    "            # Extract relevant bitstring samples for the current section\n",
    "            for k, v in results[\"samples\"][delta][p].items():\n",
    "                samples_sec[k[sec*nq:(sec+1)*nq]] += v\n",
    "\n",
    "            # Compute the MaxCut objective for the extracted samples\n",
    "            postprocessing[delta][p][sec] = objective_MaxCut(samples_sec, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "            # Apply error mitigation to the samples\n",
    "            # new_samples = mitigate(samples_sec, results[\"G\"], random=False)\n",
    "\n",
    "            # Compute the MaxCut objective after error mitigation\n",
    "            # postprocessing_mitig[delta][p][sec] = objective_MaxCut(new_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Store the postprocessing results\n",
    "results[\"postprocessing\"] = postprocessing\n",
    "# results[\"postprocessing_mitig\"] = postprocessing_mitig\n",
    "\n",
    "# Generate random bitstring samples for comparison (10,000 random samples)\n",
    "rand_samples = random_samples(1_000, nq)\n",
    "\n",
    "# Compute MaxCut objective for the random samples\n",
    "results[\"random\"] = objective_MaxCut(rand_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Apply error mitigation to the random samples and compute MaxCut objective\n",
    "# results[\"random_mitig\"] = objective_MaxCut(mitigate(rand_samples, results[\"G\"], random=False), results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Save the updated results back to a NumPy binary file\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC{extra}.npy\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d0c477da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: np.float64(0.7535529032583002)}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{p:results[\"postprocessing\"][results[\"Deltas\"][0]][p][0][\"r\"] for p in results[\"ps\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "65a922ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8459046180188361)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"random\"][\"r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab91179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job completed successfully!\n",
      "Number of shots: 100\n"
     ]
    }
   ],
   "source": [
    "# Wait for job to complete and retrieve results\n",
    "qnx.jobs.wait_for(result_ref)\n",
    "job_result = qnx.jobs.results(result_ref)[0].download_result()\n",
    "print(\"Job completed successfully!\")\n",
    "print(f\"Number of shots: {len(job_result.results)}\")\n",
    "\n",
    "results[\"job_id\"] = str(result_ref)\n",
    "# Store job ID for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d27a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approximation ratio (r): 0.9176\n",
      "Probability of optimal: 0.1800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Store results in structured format (matching FC-Experiments.ipynb)\n",
    "# Format: results[\"samples\"][delta][p] = {bitstring: count}\n",
    "delta_tuple = results[\"Deltas\"][0]  # Get the delta tuple\n",
    "if \"samples\" not in results:\n",
    "    results[\"samples\"] = {}\n",
    "\n",
    "if delta_tuple not in results[\"samples\"]:\n",
    "    results[\"samples\"][delta_tuple] = {}\n",
    "\n",
    "results[\"samples\"][delta_tuple][p] = samples_dict\n",
    "\n",
    "# Calculate approximation ratio using the objective_MaxCut function\n",
    "postprocessing = objective_MaxCut(samples_dict, graph, optimal_sol)\n",
    "\n",
    "print(f\"\\nResults for p={p}, delta_beta={delta_beta}, delta_gamma={delta_gamma}:\")\n",
    "print(f\"Approximation ratio (r): {postprocessing['r']:.4f}\")\n",
    "print(f\"Probability of optimal: {postprocessing['probability']:.4f}\")\n",
    "print(f\"\\nTop 10 most common bitstrings:\")\n",
    "for bitstring, count in sorted(samples_dict.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    energy = cost_maxcut(bitstring, {(i, j): graph[i][j][\"weight\"] for i, j in graph.edges})\n",
    "    print(f\"  {bitstring}: {count:4d} ({100*count/len(outcomes):5.1f}%) - energy: {energy:.2f}\")\n",
    "\n",
    "# Save results to file\n",
    "import os\n",
    "os.makedirs(f\"./Data/{backend_name}\", exist_ok=True)\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n",
    "print(f\"\\n✓ Results saved to ./Data/{backend_name}/{nq}_FC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07418108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e65540b",
   "metadata": {},
   "source": [
    "# Load and Postprocess Saved Results\n",
    "\n",
    "Load previously saved results and perform postprocessing analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e845809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved results\n",
    "backend_name = \"helios_1e_lite\"\n",
    "nq = 56\n",
    "\n",
    "results = np.load(f\"./Data/{backend_name}/{nq}_FC.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Get metadata\n",
    "graph = results[\"G\"]\n",
    "optimal_sol = results[\"optimal\"]\n",
    "ps = results[\"ps\"]\n",
    "deltas = results[\"Deltas\"]\n",
    "\n",
    "print(f\"Loaded results for nq={nq}, backend={backend_name}\")\n",
    "print(f\"QAOA depths (p): {ps}\")\n",
    "print(f\"Deltas: {deltas}\")\n",
    "print(f\"Number of samples collected: {sum(len(results['samples'][d]) for d in results['samples'])}\")\n",
    "\n",
    "# Postprocess all results\n",
    "postprocessing_all = {}\n",
    "for delta in results[\"samples\"]:\n",
    "    postprocessing_all[delta] = {}\n",
    "    for p in results[\"samples\"][delta]:\n",
    "        samples = results[\"samples\"][delta][p]\n",
    "        postproc = objective_MaxCut(samples, graph, optimal_sol)\n",
    "        postprocessing_all[delta][p] = postproc\n",
    "        \n",
    "        print(f\"\\nDelta={delta}, p={p}:\")\n",
    "        print(f\"  Approximation ratio (r): {postproc['r']:.4f}\")\n",
    "        print(f\"  Probability of optimal: {postproc['probability']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256eaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results vs p\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract r values for each delta and p\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for delta in postprocessing_all:\n",
    "    ps_sorted = sorted(postprocessing_all[delta].keys())\n",
    "    r_values = [postprocessing_all[delta][p]['r'] for p in ps_sorted]\n",
    "    prob_values = [postprocessing_all[delta][p]['probability'] for p in ps_sorted]\n",
    "    \n",
    "    delta_label = f\"δ_β={delta[0]:.2f}, δ_γ={delta[1]:.2f}\" if isinstance(delta, tuple) else f\"δ={delta:.2f}\"\n",
    "    \n",
    "    # Plot approximation ratio\n",
    "    ax1.plot(ps_sorted, r_values, 'o-', markersize=8, linewidth=2, label=delta_label)\n",
    "    \n",
    "    # Plot probability of optimal\n",
    "    ax2.plot(ps_sorted, prob_values, 's-', markersize=8, linewidth=2, label=delta_label)\n",
    "\n",
    "# Format plot 1\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Random baseline')\n",
    "ax1.set_xlabel('QAOA Depth (p)', fontsize=12)\n",
    "ax1.set_ylabel('Approximation Ratio (r)', fontsize=12)\n",
    "ax1.set_title(f'QAOA Performance vs Depth\\\\n{nq}-qubit FC MaxCut on {backend_name}', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.set_ylim([0.4, 1.05])\n",
    "\n",
    "# Format plot 2\n",
    "ax2.set_xlabel('QAOA Depth (p)', fontsize=12)\n",
    "ax2.set_ylabel('Probability of Optimal Solution', fontsize=12)\n",
    "ax2.set_title(f'Optimal Solution Sampling vs Depth\\\\n{nq}-qubit FC MaxCut', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SUMMARY: {nq}-qubit FC MaxCut on {backend_name}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Delta':<20} {'p':<5} {'r (ratio)':<12} {'P(optimal)':<15} {'Shots':<10}\")\n",
    "print(\"-\"*80)\n",
    "for delta in postprocessing_all:\n",
    "    delta_str = f\"({delta[0]:.2f}, {delta[1]:.2f})\" if isinstance(delta, tuple) else f\"{delta:.2f}\"\n",
    "    for p in sorted(postprocessing_all[delta].keys()):\n",
    "        r = postprocessing_all[delta][p]['r']\n",
    "        prob = postprocessing_all[delta][p]['probability']\n",
    "        n_shots = sum(postprocessing_all[delta][p]['results'][:, 2])\n",
    "        print(f\"{delta_str:<20} {p:<5} {r:<12.4f} {prob:<15.4f} {int(n_shots):<10}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
