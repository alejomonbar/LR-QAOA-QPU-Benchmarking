{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "from docplex.mp.model import Model\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Sampler\n",
    "service = QiskitRuntimeService()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = {}\n",
    "backends[\"ibm_marrakesh\"] = service.backend('ibm_marrakesh')\n",
    "backends[\"ibm_fez\"] = service.backend('ibm_fez')\n",
    "backends[\"ibm_torino\"] = service.backend('ibm_torino')\n",
    "backends[\"ibm_brisbane\"] = service.backend('ibm_brisbane')\n",
    "\n",
    "backends[\"mps\"] = service.backend(\"simulator_mps\")\n",
    "backends[\"qasm_simulator\"] = AerSimulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main 1D-Chain IBM QPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits_in_line = {}\n",
    "# Eagle device\n",
    "qubits_1D_Eagle = list(range(13,-1,-1)) + [14] + list(range(18,33)) + [36] + list(range(51,36,-1)) + [52] + list(range(56,71)) + [74] + list(range(89,74,-1)) + [90] + list(range(94,109)) + [112] + list(range(126,112,-1))\n",
    "\n",
    "for backend in backends.keys():\n",
    "    if backend[:3] == \"ibm\" and backend != \"ibm_torino\":\n",
    "        qubits_in_line[backend] = qubits_1D_Eagle\n",
    "\n",
    "# Heron device\n",
    "qubits_in_line[\"ibm_torino\"] = list(range(14,-1,-1)) + [15] + list(range(19,34)) + [37] + list(range(52,37,-1)) + [53] + list(range(57,72)) + [75] + list(range(90,75,-1)) + [91] + list(range(95,110)) + [113] + list(range(128,113,-1)) + [129]\n",
    "qubits_in_line[\"ibm_fez\"] = list(range(0,16)) + [19] + list(range(35,20,-1)) + [36] + list(range(41,56)) + [59] + list(range(75,60,-1)) + [76] + list(range(81,96)) + [99] + list(range(115,100,-1)) + [116] + list(range(121,136)) + [139] + list(range(155,139,-1))\n",
    "qubits_in_line[\"ibm_marrakesh\"] = list(range(0,16)) + [19] + list(range(35,20,-1)) + [36] + list(range(41,56)) + [59] + list(range(75,60,-1)) + [76] + list(range(81,96)) + [99] + list(range(115,100,-1)) + [116] + list(range(121,136)) + [139] + list(range(155,139,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAOA Circuit - SWAP network strategy for 1D-Chain connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "import numpy as np\n",
    "\n",
    "def layer_1D_full_Graph(G, gamma):\n",
    "    \"\"\"\n",
    "    Constructs a single layer of the QAOA circuit for a 1D swap network.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The problem graph, where nodes represent qubits, \n",
    "                          and edges contain weights for interactions.\n",
    "    - gamma (float): The parameter controlling the evolution of the cost Hamiltonian.\n",
    "\n",
    "    Returns:\n",
    "    - layer (QuantumCircuit): A quantum circuit implementing the ZZ evolution with swaps.\n",
    "    \"\"\"\n",
    "    num_qubits = G.number_of_nodes()\n",
    "    \n",
    "    # Track current qubit permutation due to swaps\n",
    "    permutation = np.arange(num_qubits)\n",
    "    \n",
    "    # Normalize edge weights\n",
    "    max_weight = np.max(np.abs([G[i][j][\"weight\"] for i, j in G.edges()]))\n",
    "\n",
    "    # Initialize the quantum circuit for one layer\n",
    "    layer = QuantumCircuit(num_qubits)\n",
    "    \n",
    "    # Implement the swap network with RZZ gates\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(i % 2, num_qubits - 1, 2):\n",
    "            # Apply a controlled-X (CNOT) gate\n",
    "            layer.cx(j, j + 1)\n",
    "            \n",
    "            # Apply a weighted RZ rotation on the second qubit\n",
    "            layer.rz(2 * G[permutation[j]][permutation[j + 1]][\"weight\"] * gamma / max_weight, j + 1)\n",
    "            \n",
    "            # Undo the CX gate sequence to restore original states\n",
    "            layer.cx(j + 1, j)\n",
    "            layer.cx(j, j + 1)\n",
    "            \n",
    "            # Update the permutation due to the swap\n",
    "            permutation[[j, j + 1]] = permutation[[j + 1, j]]\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def qaoa_swap_network(G, gammas, betas):\n",
    "    \"\"\"\n",
    "    Constructs a full QAOA circuit using a swap network for a 1D architecture.\n",
    "\n",
    "    This is useful for fully connected problems (e.g., complete graphs) where\n",
    "    all qubits need pairwise interactions.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The problem graph with weighted edges.\n",
    "    - gammas (list of floats): The QAOA parameters for cost Hamiltonian evolution.\n",
    "    - betas (list of floats): The QAOA parameters for mixer Hamiltonian evolution.\n",
    "\n",
    "    Returns:\n",
    "    - circ (QuantumCircuit): The full QAOA quantum circuit.\n",
    "    \"\"\"\n",
    "    num_qubits = G.number_of_nodes()\n",
    "    p = len(gammas)  # Number of QAOA layers\n",
    "\n",
    "    # Initialize the QAOA quantum circuit\n",
    "    circ = QuantumCircuit(num_qubits)\n",
    "\n",
    "    # Apply the initial layer of Hadamard gates to all qubits\n",
    "    for i in range(num_qubits):\n",
    "        circ.h(i)\n",
    "    # Function to generate each layer\n",
    "    layer = lambda gamma: layer_1D_full_Graph(G, gamma)\n",
    "\n",
    "    # Add p layers of QAOA\n",
    "    for pi in range(p):\n",
    "        # Apply the cost Hamiltonian evolution (ZZ interactions with swaps)\n",
    "        circ = circ.compose(layer(gammas[pi]), \n",
    "                            range(num_qubits) if not pi % 2 else reversed(range(num_qubits)))\n",
    "        # Apply the mixer Hamiltonian evolution (RX rotations)\n",
    "        circ.rx(-2 * betas[pi], range(num_qubits))    \n",
    "    return circ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_maxcut(bitstring, weights):\n",
    "    \"\"\"\n",
    "    Computes the cost of a given bitstring solution for the Max-Cut problem.\n",
    "\n",
    "    Parameters:\n",
    "    bitstring (str): A binary string representing a partition of the graph nodes (e.g., \"1010\").\n",
    "    weights (dict): A dictionary where keys are edge tuples (i, j) and values are edge weights.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed cost of the Max-Cut solution.\n",
    "    \"\"\"\n",
    "    cost = 0  # Initialize the cost\n",
    "    \n",
    "    # Iterate through all edges in the graph\n",
    "    for i, j in weights.keys():\n",
    "        # Check if the nodes i and j are in different partitions (cut condition)\n",
    "        if bitstring[i] + bitstring[j] in [\"10\", \"01\"]:\n",
    "            cost += weights[i, j]  # Add the edge weight to the cost\n",
    "\n",
    "    return cost  # Return the total cut cost\n",
    "\n",
    "\n",
    "def objective_MaxCut(samples_dict, G, optimal):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a quantum algorithm for the Max-Cut problem.\n",
    "\n",
    "    Parameters:\n",
    "    samples_dict (dict): A dictionary where keys are bitstrings (binary solutions), \n",
    "                         and values are their occurrence counts.\n",
    "    G (networkx.Graph): The input weighted graph where edges represent cut costs.\n",
    "    optimal (str): The optimal bitstring solution found by classical solvers (e.g., CPLEX).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing:\n",
    "        - \"results\": A numpy array with computed cost, normalized cost ratio, and counts.\n",
    "        - \"G\": The input graph G.\n",
    "        - \"weights\": The edge weights extracted from G.\n",
    "        - \"max_cut\": The cost of the optimal Max-Cut solution.\n",
    "        - \"r\": The expected approximation ratio.\n",
    "        - \"probability\": The probability of sampling the optimal solution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract weights from the graph's edges\n",
    "    weights = {(i, j): (G[i][j][\"weight\"] if len(G[i][j]) != 0 else 1) for i, j in G.edges}\n",
    "    \n",
    "    # Compute the cost of the optimal Max-Cut solution\n",
    "    max_cost = cost_maxcut(optimal, weights)\n",
    "\n",
    "    results = []  # Stores results in the form [cost, ratio, counts]\n",
    "    probability = 0  # Tracks probability of sampling the optimal solution\n",
    "\n",
    "    # Iterate through all sampled bitstrings\n",
    "    for bitstring, counts in samples_dict.items():\n",
    "        cost = cost_maxcut(bitstring, weights)  # Compute cost of the given bitstring\n",
    "        r = cost / max_cost  # Compute the cost ratio relative to the optimal solution\n",
    "        results.append([cost, r, counts])  # Store results\n",
    "        \n",
    "        # If this bitstring matches the optimal cost, update probability\n",
    "        if abs(cost - max_cost) < 1e-6:\n",
    "            probability += counts\n",
    "        \n",
    "        # Check if a better-than-optimal solution appears (sanity check)\n",
    "        if cost > max_cost:\n",
    "            print(f\"There is a better cost than that of CPLEX: {cost - max_cost}\")\n",
    "\n",
    "    # Convert results to a NumPy array for easy computation\n",
    "    results = np.array(results)\n",
    "\n",
    "    # Total number of shots (total sampled solutions)\n",
    "    shots = np.sum(results[:, 2])\n",
    "\n",
    "    # Compute the expected approximation ratio: (weighted sum of costs) / (shots * max_cost)\n",
    "    rT = np.sum(results[:, 0] * results[:, 2]) / (shots * max_cost)\n",
    "\n",
    "    # Normalize the probability of sampling the optimal solution\n",
    "    probability /= shots\n",
    "\n",
    "    # Return results in a structured dictionary\n",
    "    return {\n",
    "        \"results\": np.array(results),\n",
    "        \"G\": G,\n",
    "        \"weights\": weights,\n",
    "        \"max_cut\": max_cost,\n",
    "        \"r\": rT,\n",
    "        \"probability\": probability\n",
    "    }\n",
    "\n",
    "def mitigate(samples_dict, G, random=False):\n",
    "    \"\"\"\n",
    "    Applies error mitigation by flipping individual bits in sampled solutions \n",
    "    to find better Max-Cut solutions.\n",
    "\n",
    "    Parameters:\n",
    "    samples_dict (dict): A dictionary where keys are bitstrings (binary solutions), \n",
    "                         and values are their occurrence counts.\n",
    "    G (networkx.Graph): The input weighted graph where edges represent cut costs.\n",
    "    random (bool, optional): If True, randomizes the order in which qubits are flipped.\n",
    "                             Default is False (systematic flipping).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of improved bitstring samples with their updated counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a mapping to flip bits ('0' -> '1', '1' -> '0')\n",
    "    change = {\"0\": \"1\", \"1\": \"0\"}\n",
    "\n",
    "    # Get the number of nodes (qubits)\n",
    "    nq = G.number_of_nodes()\n",
    "\n",
    "    # Extract weights from the graph's edges\n",
    "    weights = {(i, j): (G[i][j][\"weight\"] if len(G[i][j]) != 0 else 1) for i, j in G.edges}\n",
    "\n",
    "    # Dictionary to store new (improved) samples\n",
    "    new_samples = defaultdict(int)\n",
    "\n",
    "    # Iterate over all bitstring samples\n",
    "    for bitstring, counts in samples_dict.items():\n",
    "        for _ in range(counts):  # Process each occurrence of the bitstring separately\n",
    "            best_string = bitstring  # Initialize the best solution as the current one\n",
    "            best_cost = cost_maxcut(bitstring, weights)  # Compute its cost\n",
    "            \n",
    "            # Create an ordered list of qubits (nodes) to consider flipping\n",
    "            list_qubits = np.arange(nq)\n",
    "            \n",
    "            # If random flipping is enabled, shuffle the qubit order\n",
    "            if random:\n",
    "                np.random.shuffle(list_qubits)\n",
    "\n",
    "            # Try flipping each qubit and check if the cost improves\n",
    "            for qi in list_qubits:\n",
    "                # Flip the bit at position qi\n",
    "                new_string = \"\".join((change[i] if n == qi else i) for n, i in enumerate(best_string))\n",
    "                new_cost = cost_maxcut(new_string, weights)\n",
    "\n",
    "                # If the new configuration gives a better cost, update the best solution\n",
    "                if new_cost > best_cost:\n",
    "                    best_string = new_string\n",
    "                    best_cost = new_cost\n",
    "            \n",
    "            # Store the improved bitstring in the new_samples dictionary\n",
    "            new_samples[best_string] += 1\n",
    "\n",
    "    return new_samples  # Return the mitigated samples\n",
    "\n",
    "def random_samples(num_samples, n_qubits):\n",
    "    \"\"\"\n",
    "    Generates random bitstring samples for a given number of qubits.\n",
    "\n",
    "    Parameters:\n",
    "    num_samples (int): The number of random bitstrings to generate.\n",
    "    n_qubits (int): The number of qubits (length of each bitstring).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are randomly generated bitstrings \n",
    "          and values are their occurrence counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    random_samples = defaultdict(int)  # Dictionary to store bitstrings and their counts\n",
    "\n",
    "    # Generate random bitstrings and count their occurrences\n",
    "    for _ in range(num_samples):\n",
    "        bitstring = \"\".join(str(i) for i in np.random.choice([0, 1], n_qubits))  # Generate a random bitstring\n",
    "        random_samples[bitstring] += 1  # Increment count for the generated bitstring\n",
    "\n",
    "    return random_samples  # Return the dictionary of samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = np.load(\"./Data/WMC_FC.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  p: 3  ----------\n",
      "---------  p: 4  ----------\n",
      "---------  p: 5  ----------\n",
      "---------  p: 6  ----------\n",
      "---------  p: 7  ----------\n",
      "---------  p: 8  ----------\n",
      "---------  p: 9  ----------\n",
      "---------  p: 10  ----------\n",
      "---------  p: 13  ----------\n",
      "---------  p: 15  ----------\n",
      "---------  p: 20  ----------\n",
      "Delta: -------  0.63 ----------- \n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Define the backend for quantum computation (uncomment the desired backend)\n",
    "# backend_name = \"ibm_brisbane\"\n",
    "# backend_name = \"ibm_sherbrooke\"\n",
    "# backend_name = \"ibm_kyiv\"\n",
    "# backend_name = \"ibm_nazca\"\n",
    "# backend_name = \"ibm_osaka\"\n",
    "# backend_name = \"ibm_kyoto\"\n",
    "# backend_name = \"ibm_torino\"\n",
    "# backend_name = \"ibm_fez\"\n",
    "backend_name = \"ibm_marrakesh\"  # Selected backend\n",
    "# backend_name = \"qasm_simulator\"  # Uncomment to use a classical simulator\n",
    "\n",
    "# Get the backend from the available backends dictionary\n",
    "backend = backends[backend_name]\n",
    "\n",
    "# Number of qubits used in the problem\n",
    "nq = 20\n",
    "\n",
    "# Define qubit mapping for the QASM simulator\n",
    "qubits_in_line[\"qasm_simulator\"] = range(nq)\n",
    "\n",
    "# Define delta values for parameter tuning in QAOA (uncomment as needed)\n",
    "# deltas = [0.05, 0.1, 0.2, 0.3, 0.5, 0.63] # For 50 qubits\n",
    "# deltas = np.linspace(0.4, 1, 10)  # Generates evenly spaced deltas\n",
    "# deltas = [0.3]  # Alternative single delta value\n",
    "deltas = [0.63]  # Chosen delta for this experiment\n",
    "\n",
    "# Store delta values in results\n",
    "results[\"Deltas\"] = deltas\n",
    "\n",
    "# Load the problem graph for the given number of qubits\n",
    "G = problems[nq][\"G\"]\n",
    "results[\"G\"] = G  # Store the graph in results\n",
    "\n",
    "# Get the device-specific qubit layout\n",
    "qubits_device = qubits_in_line[backend_name] \n",
    "\n",
    "# Calculate the number of sections (repetitions) based on available qubits\n",
    "reps = len(qubits_device) // (nq + 1) if backend_name != \"qasm_simulator\" else 1\n",
    "results[\"sections\"] = reps  # Store the number of sections\n",
    "\n",
    "# Determine the maximum number of qubits available in the backend\n",
    "max_qubits = backend.num_qubits if backend_name != \"qasm_simulator\" else nq\n",
    "\n",
    "# Define the number of QAOA layers (ps values) to test\n",
    "# ps = [0, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25, 30, 40, 50]  # Alternative set\n",
    "ps = [3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20]  # Selected set of layers\n",
    "# ps = [3, 5, 10, 20]  # Alternative smaller set\n",
    "# ps = [20]  # Single depth experiment\n",
    "\n",
    "# Store layer values and optimal solution in results\n",
    "results[\"ps\"] = ps\n",
    "results[\"optimal\"] = problems[nq][\"sol\"]\n",
    "\n",
    "# Dictionary to store transpiled circuits\n",
    "circuits_transpiled = {}\n",
    "\n",
    "# Loop through different values of p (QAOA layers)\n",
    "for p in ps:\n",
    "    print(f\"---------  p: {p}  ----------\")  # Print progress\n",
    "\n",
    "    # Define QAOA parameters as symbolic variables\n",
    "    betas = ParameterVector(\"betas\", p)\n",
    "    gammas = ParameterVector(\"gammas\", p)\n",
    "\n",
    "    # Create the QAOA circuit using a swap network approach\n",
    "    qc = qaoa_swap_network(G, gammas, betas)\n",
    "\n",
    "    # Initialize a quantum circuit matching the backend qubit count\n",
    "    circ = QuantumCircuit(max_qubits, reps * nq)\n",
    "\n",
    "    # Track qubits used in the circuit\n",
    "    total_qubits_used = []\n",
    "\n",
    "    # Embed the circuit into the available hardware qubits\n",
    "    for i in range(reps):\n",
    "        qubits_used = qubits_device[nq * i + i : nq * (i + 1) + i]\n",
    "        # Alternative qubit assignment:\n",
    "        # qubits_used = qubits_device[nq*i: nq*(i+1)]\n",
    "\n",
    "        # Attach the QAOA circuit to the selected qubits\n",
    "        circ = circ.compose(qc, qubits_used)\n",
    "\n",
    "        # Store the qubits used\n",
    "        total_qubits_used += qubits_used\n",
    "\n",
    "    # Transpile the circuit for the target backend (no optimization applied)\n",
    "    circ_device = transpile(circ, backend, optimization_level=0, initial_layout=range(max_qubits))\n",
    "\n",
    "    # Add measurement operations to the circuit\n",
    "    circ_device.measure(total_qubits_used, reversed(range(reps * nq)) if not p % 2 else range(nq * reps))\n",
    "\n",
    "    # Store the transpiled circuit\n",
    "    circuits_transpiled[p] = circ_device\n",
    "\n",
    "# Store the total qubits used in the results\n",
    "results[\"total_qubits_used\"] = total_qubits_used\n",
    "\n",
    "# List to store final circuits with assigned parameters\n",
    "circuits = []\n",
    "\n",
    "# Iterate over different delta values\n",
    "for delta in deltas:\n",
    "    print(f\"Delta: -------  {round(delta, 2)} ----------- \")\n",
    "\n",
    "    # Iterate over different QAOA depths (p values)\n",
    "    for p in ps:\n",
    "        # Compute the betas and gammas based on the delta value\n",
    "        betas = list(np.arange(1, p + 1)[::-1] * delta / p)\n",
    "        gammas = list(np.arange(1, p + 1) * delta / p)\n",
    "\n",
    "        # Assign the computed parameters to the transpiled circuit\n",
    "        backend_circ = circuits_transpiled[p].assign_parameters(np.concatenate((betas, gammas)))\n",
    "\n",
    "        # Store the final circuit\n",
    "        circuits.append(backend_circ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/d4kyjysx1xgdrrs6zzs63s180000gn/T/ipykernel_88515/3126640788.py:3: DeprecationWarning: backend.run() and related sessions methods are deprecated  as of qiskit-ibm-runtime 0.23 and will be removed no sooner than 6 months after the release date. More details can be found in the primitives migration guide https://docs.quantum.ibm.com/migration-guides/qiskit-runtime.\n",
      "  submit_job = backends[backend_name].run(circuits, shots=shots)\n"
     ]
    }
   ],
   "source": [
    "# Define the number of shots (number of times the quantum circuit is executed)\n",
    "shots = 1000\n",
    "\n",
    "# Check if the selected backend is NOT the QASM simulator (i.e., using real quantum hardware)\n",
    "if backend_name != \"qasm_simulator\":\n",
    "    # Submit the quantum job to the selected IBMQ backend\n",
    "    submit_job = backends[backend_name].run(circuits, shots=shots)\n",
    "\n",
    "    # Store the job ID in results to track and retrieve it later\n",
    "    results[\"id\"] = submit_job.job_id()  \n",
    "else:\n",
    "    # If using the QASM simulator, execute the circuits locally and get the results immediately\n",
    "    dict_results = backends[backend_name].run(circuits, shots=shots).result().get_counts()\n",
    "\n",
    "    # Store the results in a structured dictionary format\n",
    "    # The results dictionary is indexed first by delta, then by QAOA depth (p), \n",
    "    # and finally by the measurement outcomes (bitstrings) with their corresponding counts.\n",
    "    results[\"samples\"] = {\n",
    "        delta: {\n",
    "            p: {k: v for k, v in dict_results[i + nd * len(ps)].items()}\n",
    "            for i, p in enumerate(results[\"ps\"])\n",
    "        }\n",
    "        for nd, delta in enumerate(results[\"Deltas\"])\n",
    "    }\n",
    "\n",
    "# Save the results dictionary as a NumPy binary file for future use\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve QPU experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the backend name (IBM quantum processor being used)\n",
    "backend_name = \"ibm_marrakesh\"\n",
    "\n",
    "# Define the number of qubits used in the computation\n",
    "nq = 20\n",
    "\n",
    "# Load previously saved results from a NumPy binary file\n",
    "results = np.load(f\"./Data/{backend_name}/{nq}_FC.npy\", allow_pickle=True).item()\n",
    "\n",
    "# If running on real quantum hardware (not a simulator)\n",
    "if backend_name != \"qasm_simulator\":\n",
    "    # Retrieve the job results from IBM's quantum service using the stored job ID\n",
    "    jobs = service.job(job_id=results[\"id\"]).result()\n",
    "\n",
    "    # Extract the measurement counts (bitstring results) from the job results\n",
    "    dict_results = jobs.get_counts()\n",
    "\n",
    "    # Store the results in a structured dictionary format\n",
    "    # - Organized by delta values and QAOA depth (p)\n",
    "    # - The bitstrings (measurement outcomes) are mapped to their corresponding counts\n",
    "    results[\"samples\"] = {\n",
    "        delta: {\n",
    "            p: {k: v for k, v in dict_results[i + nd * len(ps)].items()}\n",
    "            for i, p in enumerate(results[\"ps\"])\n",
    "        }\n",
    "        for nd, delta in enumerate(results[\"Deltas\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- p = 3 -------------\n",
      "----------- p = 4 -------------\n",
      "----------- p = 5 -------------\n",
      "----------- p = 6 -------------\n",
      "----------- p = 7 -------------\n",
      "----------- p = 8 -------------\n",
      "----------- p = 9 -------------\n",
      "----------- p = 10 -------------\n",
      "----------- p = 13 -------------\n",
      "----------- p = 15 -------------\n",
      "----------- p = 20 -------------\n"
     ]
    }
   ],
   "source": [
    "# Get the number of nodes (qubits) in the graph problem\n",
    "nq = results[\"G\"].number_of_nodes()\n",
    "\n",
    "# Get the number of sections (used for processing multiple groups of qubits in a single execution)\n",
    "sections = results[\"sections\"]\n",
    "\n",
    "# Initialize dictionaries to store postprocessing results\n",
    "postprocessing = {}\n",
    "postprocessing_mitig = {}\n",
    "\n",
    "# Iterate over different delta values (used for QAOA parameter tuning)\n",
    "for delta in results[\"samples\"]:\n",
    "    postprocessing[delta] = {}\n",
    "    postprocessing_mitig[delta] = {}\n",
    "\n",
    "    # Iterate over different QAOA depths (p values)\n",
    "    for p in results[\"samples\"][delta]:\n",
    "        print(f\"----------- p = {p} -------------\")\n",
    "        postprocessing[delta][p] = {}\n",
    "        postprocessing_mitig[delta][p] = {}\n",
    "\n",
    "        # Iterate over different sections (to handle multiple independent executions within a job)\n",
    "        for sec in range(sections):\n",
    "            samples_sec = defaultdict(int)\n",
    "\n",
    "            # Extract relevant bitstring samples for the current section\n",
    "            for k, v in results[\"samples\"][delta][p].items():\n",
    "                samples_sec[k[sec*nq:(sec+1)*nq]] += v\n",
    "\n",
    "            # Compute the MaxCut objective for the extracted samples\n",
    "            postprocessing[delta][p][sec] = objective_MaxCut(samples_sec, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "            # Apply error mitigation to the samples\n",
    "            new_samples = mitigate(samples_sec, results[\"G\"], random=False)\n",
    "\n",
    "            # Compute the MaxCut objective after error mitigation\n",
    "            postprocessing_mitig[delta][p][sec] = objective_MaxCut(new_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Store the postprocessing results\n",
    "results[\"postprocessing\"] = postprocessing\n",
    "results[\"postprocessing_mitig\"] = postprocessing_mitig\n",
    "\n",
    "# Generate random bitstring samples for comparison (10,000 random samples)\n",
    "rand_samples = random_samples(10_000, nq)\n",
    "\n",
    "# Compute MaxCut objective for the random samples\n",
    "results[\"random\"] = objective_MaxCut(rand_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Apply error mitigation to the random samples and compute MaxCut objective\n",
    "results[\"random_mitig\"] = objective_MaxCut(mitigate(rand_samples, results[\"G\"], random=False), results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Save the updated results back to a NumPy binary file\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantinuum experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import qiskit_to_tk, tk_to_qiskit\n",
    "from pytket.circuit.display import render_circuit_jupyter\n",
    "from pytket.extensions.qiskit.tket_backend import TketBackend\n",
    "from pytket.extensions.quantinuum import QuantinuumBackend\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load the Quantinuum backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = {}\n",
    "# backends[\"H2-1\"] = QuantinuumBackend(device_name=\"H2-1\") # QPU with 56 qubits\n",
    "# backends[\"H2-1\"].login()\n",
    "backends[\"H2-1E\"] = QuantinuumBackend(device_name=\"H2-1E\") # Emulator of the 32 qubits QPU\n",
    "backends[\"H2-1E\"].login()\n",
    "# backends[\"H1-1E\"] = QuantinuumBackend(device_name=\"H1-1E\") # Emulator of the 20 qubits QPU\n",
    "# backends[\"H1-1E\"].login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 QAOA Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaoa_maxcut(G, gammas, betas):\n",
    "    # Get the number of nodes in the graph\n",
    "    nodes = len(G.nodes())\n",
    "    \n",
    "    # Extract edges as tuples (i, j)\n",
    "    edges = [(i, j) for i, j in G.edges()]\n",
    "    \n",
    "    # Find the maximum absolute edge weight for normalization\n",
    "    max_w = np.max(np.abs([G[i][j][\"weight\"] for i, j in G.edges()]))\n",
    "    \n",
    "    # Number of QAOA layers (depth of the ansatz)\n",
    "    layers = len(gammas)\n",
    "    \n",
    "    # Create a quantum circuit with 'nodes' qubits\n",
    "    qc = QuantumCircuit(nodes)\n",
    "    \n",
    "    # Apply Hadamard gates to all qubits to create a superposition\n",
    "    qc.h(range(nodes))\n",
    "    \n",
    "    # Iterate through QAOA layers\n",
    "    for p in range(layers):\n",
    "        # Generate a permutation to optimize circuit depth\n",
    "        permutations = np.arange(nodes)\n",
    "        \n",
    "        # Apply the ZZ-interaction gates based on the graph edges\n",
    "        for jj in range(nodes):\n",
    "            for k in range(jj % 2, nodes - 1, 2):\n",
    "                qubit_pair = (permutations[k], permutations[k+1])\n",
    "                \n",
    "                # Check if the qubit pair corresponds to an edge in the graph\n",
    "                if qubit_pair in edges or reversed(qubit_pair) in edges:\n",
    "                    # Apply an RZZ (ZZ-rotation) gate weighted by the graph edge weight\n",
    "                    qc.rzz(2 * gammas[p] * G[qubit_pair[0]][qubit_pair[1]][\"weight\"] / max_w, *qubit_pair)\n",
    "                \n",
    "                # Swap the qubits to optimize execution\n",
    "                permutations[[k, k+1]] = permutations[[k+1, k]]\n",
    "        \n",
    "        # Apply RX rotations to all qubits (single-qubit mixing gates)\n",
    "        qc.rx(-2 * betas[p], range(nodes))\n",
    "    \n",
    "    # Return the constructed quantum circuit\n",
    "    return qc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create the quantum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  p: 3  ----------\n",
      "---------  p: 4  ----------\n",
      "---------  p: 5  ----------\n",
      "Delta: -------  0.3 ----------- \n",
      "HQC -> Cost of the circuit: 28.52\n",
      "Number of ZZ gates for p=3 -> 570\n",
      "HQC -> Cost of the circuit: 36.2\n",
      "Number of ZZ gates for p=4 -> 760\n",
      "HQC -> Cost of the circuit: 43.88\n",
      "Number of ZZ gates for p=5 -> 950\n",
      "Number of ZZ gates from this experiment 45600\n",
      "HQC total 108.6\n"
     ]
    }
   ],
   "source": [
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Select backend\n",
    "backend_name = \"H2-1E\"  # Name of the quantum hardware\n",
    "# backend_name = \"qasm_simulator\"  # Uncomment this line to use a classical simulator instead\n",
    "\n",
    "backend = backends[backend_name]  # Get the backend instance\n",
    "\n",
    "# Define the number of qubits\n",
    "nq = 20\n",
    "\n",
    "# Define delta values for optimization\n",
    "# deltas = np.linspace(0.5, 0.9, 10)  # Uncomment to generate multiple delta values\n",
    "deltas = {20: [0.3]}[nq]  # Set delta values for the specific number of qubits\n",
    "# deltas = [0.63]  # Alternative fixed delta value\n",
    "\n",
    "# Store delta values in results dictionary\n",
    "results[\"Deltas\"] = deltas\n",
    "\n",
    "# Retrieve the Max-Cut problem graph for nq qubits\n",
    "G = problems[nq][\"G\"]\n",
    "results[\"G\"] = G\n",
    "\n",
    "# Number of circuit repetitions\n",
    "reps = 1\n",
    "results[\"sections\"] = reps\n",
    "\n",
    "# Define the number of shots (repetitions of measurement)\n",
    "results[\"shots\"] = 20\n",
    "\n",
    "# Define QAOA depth (p values)\n",
    "ps = [3, 4, 5]  # List of different QAOA depths to evaluate\n",
    "# ps = [1]  # Uncomment to run a simple QAOA instance\n",
    "# ps = [3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25, 30, 40, 50]  # Larger set of depths\n",
    "\n",
    "results[\"ps\"] = ps\n",
    "results[\"optimal\"] = problems[nq][\"sol\"]  # Store the optimal solution\n",
    "\n",
    "# Dictionary to store transpiled circuits\n",
    "circuits_transpiled = {}\n",
    "\n",
    "# Generate quantum circuits for each depth p\n",
    "for p in ps:\n",
    "    print(f\"---------  p: {p}  ----------\")\n",
    "    \n",
    "    # Define parameter vectors for betas and gammas\n",
    "    betas = ParameterVector(\"β\", p)\n",
    "    gammas = ParameterVector(\"γ\", p)\n",
    "    \n",
    "    # Generate the QAOA quantum circuit for Max-Cut\n",
    "    qc = qaoa_maxcut(G, gammas, betas)\n",
    "    \n",
    "    # Create a circuit with nq qubits and classical bits\n",
    "    circ = QuantumCircuit(nq, reps * nq)\n",
    "    \n",
    "    # Apply QAOA circuit to the quantum register\n",
    "    total_qubits_used = []\n",
    "    circ = circ.compose(qc, range(nq))\n",
    "    total_qubits_used = range(nq)\n",
    "    \n",
    "    # Transpile the circuit for the backend\n",
    "    # circ_device = transpile(circ, backend, optimization_level=1, initial_layout=range(nq))\n",
    "    circ_device = circ  # Keeping circuit as-is (without transpilation)\n",
    "    \n",
    "    # Add measurement to all qubits\n",
    "    circ_device.measure(total_qubits_used, range(nq))\n",
    "    \n",
    "    # Store transpiled circuit\n",
    "    circuits_transpiled[p] = circ_device\n",
    "\n",
    "# Store total qubits used in results dictionary\n",
    "results[\"total_qubits_used\"] = total_qubits_used\n",
    "\n",
    "# Prepare circuits for execution\n",
    "circuits = []\n",
    "N_ZZ_exp2 = 0  # Counter for RZZ gate operations\n",
    "HQC_T = 0  # Total HQC (hardware quantum cost)\n",
    "\n",
    "# Iterate over delta values\n",
    "for delta in deltas:\n",
    "    print(f\"Delta: -------  {round(delta,2)} ----------- \")\n",
    "    \n",
    "    for p in ps:\n",
    "        # Generate values for betas and gammas\n",
    "        betas = list(np.arange(1, p+1)[::-1] * delta / p)\n",
    "        gammas = list(np.arange(1, p+1) * delta / p)\n",
    "        \n",
    "        # Assign parameter values to the circuit\n",
    "        backend_circ = circuits_transpiled[p].assign_parameters(np.concatenate((betas, gammas)))\n",
    "        circuits.append(backend_circ)\n",
    "\n",
    "        # Calculate number of RZZ (ZZ-rotation) gates\n",
    "        N_ZZ_exp2 += results[\"shots\"] * backend_circ.count_ops().get(\"rzz\", 0)\n",
    "        \n",
    "        # Count number of 1-qubit and 2-qubit gates\n",
    "        N1q = backend_circ.count_ops().get(\"h\", 0) + backend_circ.count_ops().get(\"rx\", 0)\n",
    "        N2q = backend_circ.count_ops().get(\"rzz\", 0)\n",
    "\n",
    "        # Compute the hardware quantum cost (HQC)\n",
    "        HQC = 5 + ((N1q + 10 * N2q + 5 * nq) / 5000) * results[\"shots\"]\n",
    "\n",
    "        print(f\"HQC -> Cost of the circuit: {round(HQC,2)}\")\n",
    "        print(f\"Number of ZZ gates for p={p} -> {N2q}\")\n",
    "        \n",
    "        HQC_T += HQC  # Accumulate HQC\n",
    "    \n",
    "    print(f\"Number of ZZ gates from this experiment {N_ZZ_exp2}\")\n",
    "    print(f\"HQC total {HQC_T}\")\n",
    "\n",
    "# Convert Qiskit circuits to TKET format for compilation\n",
    "tket_circ = [qiskit_to_tk(circuit) for circuit in circuits]\n",
    "\n",
    "# Compile circuits using the backend\n",
    "compiled_circuits = [backend.get_compiled_circuit(circuit, optimisation_level=0) for circuit in tket_circ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Run the Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store job IDs (for retrieval later)\n",
    "results[\"ids\"] = []\n",
    "\n",
    "# If using the classical simulator (qasm_simulator)\n",
    "if backend_name == \"qasm_simulator\":\n",
    "    # Run the circuits on the simulator with the defined number of shots\n",
    "    dict_results = backends[backend_name].run(circuits, shots=results[\"shots\"]).result().get_counts()\n",
    "\n",
    "    # Store the measured results in a structured dictionary\n",
    "    results[\"samples\"] = {\n",
    "        delta: {\n",
    "            p: {\n",
    "                k: v for k, v in dict_results[i + nd * len(ps)].items()\n",
    "            }\n",
    "            for i, p in enumerate(results[\"ps\"])\n",
    "        }\n",
    "        for nd, delta in enumerate(results[\"Deltas\"])\n",
    "    }\n",
    "\n",
    "# If using a real quantum device\n",
    "else:\n",
    "    for circ in compiled_circuits:\n",
    "        # Submit the circuit for execution on the quantum device\n",
    "        job_id = backends[backend_name].process_circuit(circ, n_shots=results[\"shots\"])\n",
    "        \n",
    "        # Store the job ID for later retrieval of results\n",
    "        results[\"ids\"].append(job_id)\n",
    "\n",
    "# Save the results dictionary to a NumPy file for later use\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Retrieve the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set backend name and number of qubits\n",
    "backend_name = \"H2-1\"\n",
    "nq = 56\n",
    "\n",
    "# Load previously saved results from a NumPy file\n",
    "results = np.load(f\"./Data/{backend_name}/{nq}_FC.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Check if we are NOT using a simulator (i.e., real quantum hardware)\n",
    "if backend_name != \"qasm_simulator\":\n",
    "    # Initialize storage for the retrieved results\n",
    "    results[\"samples\"] = {results[\"Deltas\"][0]: {}}\n",
    "\n",
    "    # Loop through the parameter depths (p values), but only process the first one ([:1])\n",
    "    for nn, p in enumerate(results[\"ps\"][:1]):  \n",
    "        id = results[\"ids\"][nn]  # Get the job ID for the current circuit\n",
    "        \n",
    "        # Initialize a dictionary to store measurement results\n",
    "        results[\"samples\"][results[\"Deltas\"][0]][p] = defaultdict(int)\n",
    "\n",
    "        # Retrieve execution results from the quantum backend\n",
    "        samples = backends[backend_name].get_result(id).get_counts()\n",
    "\n",
    "        # Process each sample (bitstring result) and store counts\n",
    "        for sample, count in samples.items():\n",
    "            sample_string = \"\".join(str(i) for i in list(sample))  # Convert to a string format\n",
    "            results[\"samples\"][results[\"Deltas\"][0]][p][sample_string] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_name = \"H2-1\"\n",
    "nq = 56\n",
    "results = np.load(f\"./Data/{backend_name}/{nq}_FC.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Postprocessing the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of nodes (qubits) from the graph\n",
    "nq = results[\"G\"].number_of_nodes()\n",
    "\n",
    "# Number of problem sections for processing results\n",
    "sections = results[\"sections\"]\n",
    "\n",
    "# Dictionaries to store post-processing results (raw and mitigated)\n",
    "postprocessing = {}\n",
    "postprocessing_mitig = {}\n",
    "\n",
    "# Iterate over different values of delta (hyperparameter)\n",
    "for delta in results[\"samples\"]:\n",
    "    postprocessing[delta] = {}\n",
    "    postprocessing_mitig[delta] = {}\n",
    "\n",
    "    # Iterate over different values of p (QAOA depth)\n",
    "    for p in results[\"samples\"][delta]:\n",
    "        print(f\"----------- p = {p} -------------\")\n",
    "        postprocessing[delta][p] = {}\n",
    "        postprocessing_mitig[delta][p] = {}\n",
    "\n",
    "        # Iterate over different sections (if results are divided into sections)\n",
    "        for sec in range(sections):\n",
    "            samples_sec = defaultdict(int)  # Store counts for the current section\n",
    "\n",
    "            # Extract measurement results for the specific section\n",
    "            for k, v in results[\"samples\"][delta][p].items():\n",
    "                samples_sec[k[sec*nq:(sec+1)*nq]] += v  # Extract substring relevant to the section\n",
    "\n",
    "            # Compute MaxCut objective function for the section\n",
    "            postprocessing[delta][p][sec] = objective_MaxCut(samples_sec, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "            # Apply error mitigation to the sample results\n",
    "            new_samples = mitigate(samples_sec, results[\"G\"], random=False)\n",
    "\n",
    "            # Compute MaxCut objective function after mitigation\n",
    "            postprocessing_mitig[delta][p][sec] = objective_MaxCut(new_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Store post-processing results in the dictionary\n",
    "results[\"postprocessing\"] = postprocessing\n",
    "results[\"postprocessing_mitig\"] = postprocessing_mitig\n",
    "\n",
    "# Generate 10,000 random samples for comparison\n",
    "rand_samples = random_samples(10000, nq)\n",
    "\n",
    "# Compute MaxCut objective function for random samples (baseline comparison)\n",
    "results[\"random\"] = objective_MaxCut(rand_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Compute MaxCut objective function for mitigated random samples\n",
    "results[\"random_mitig\"] = objective_MaxCut(mitigate(rand_samples, results[\"G\"], random=False), results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Save the updated results dictionary to a file for future analysis\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. IonQ experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_braket_provider import BraketProvider\n",
    "from braket.aws import AwsQuantumTask\n",
    "\n",
    "aws_provider = BraketProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = {}\n",
    "# backends[\"ionq_harmony\"] = aws_provider.get_backend(\"Harmony\")\n",
    "backends[\"ionq_aria_2\"] = aws_provider.get_backend(\"Aria 2\")\n",
    "backends[\"ionq_forte\"] = aws_provider.get_backend(\"Forte 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  p: 2  ----------\n",
      "---------  p: 3  ----------\n",
      "---------  p: 4  ----------\n",
      "Cost of the run 24.900000000000002!!!\n",
      "Delta: -------  0.63 ----------- \n",
      "Operations for p=2: OrderedDict([('rxx', 272), ('h', 51), ('rx', 34), ('measure', 17)])\n",
      "Operations for p=3: OrderedDict([('rxx', 408), ('h', 85), ('rx', 51), ('measure', 17)])\n",
      "Operations for p=4: OrderedDict([('rxx', 544), ('h', 119), ('rx', 68), ('measure', 17)])\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Choose the backend (quantum processor) to use for the computation\n",
    "# Uncomment one of the following lines to select the desired backend:\n",
    "# backend_name = \"ionq_harmony\"\n",
    "# backend_name = \"ionq_aria_2\"\n",
    "backend_name = \"ionq_forte\"\n",
    "\n",
    "# Get the backend object from the available backends\n",
    "backend = backends[backend_name]\n",
    "\n",
    "# Number of qubits in the problem instance\n",
    "nq = 17\n",
    "\n",
    "# Define delta values (parameter controlling the optimization process)\n",
    "# Commented out are alternative delta values for different qubit numbers\n",
    "# deltas = [0.05, 0.1, 0.2, 0.3, 0.5, 0.63]  # For 50 qubits\n",
    "# np.linspace(0.4, 1, 10) generates 10 evenly spaced values between 0.4 and 1\n",
    "# deltas = [0.3]\n",
    "deltas = [0.63]\n",
    "\n",
    "# Store delta values in the results dictionary\n",
    "results[\"Deltas\"] = deltas\n",
    "\n",
    "# Retrieve the problem graph associated with the specified number of qubits\n",
    "G = problems[nq][\"G\"]\n",
    "results[\"G\"] = G  # Store the graph in results\n",
    "\n",
    "# Number of repetitions (sections) in the quantum circuit\n",
    "reps = 1\n",
    "results[\"sections\"] = reps\n",
    "\n",
    "# Number of measurement shots per experiment\n",
    "results[\"shots\"] = 100\n",
    "\n",
    "# Define the set of qubits available on the device\n",
    "qubits_device = list(range(25))  # The first 25 qubits\n",
    "\n",
    "# Determine the maximum number of qubits available on the backend\n",
    "max_qubits = backend.num_qubits if backend_name != \"qasm_simulator\" else nq\n",
    "max_qubits = nq  # Ensure max_qubits is set to the problem size\n",
    "\n",
    "# Define the number of layers (p) in the QAOA algorithm\n",
    "ps = [2, 3, 4]\n",
    "\n",
    "# Store the selected p values in the results dictionary\n",
    "results[\"ps\"] = ps\n",
    "\n",
    "# Store the optimal solution for comparison\n",
    "results[\"optimal\"] = problems[nq][\"sol\"]\n",
    "\n",
    "# Define the cost per shot for different backends\n",
    "shot_cost = {\"ionq_aria_2\": 0.03, \"ionq_forte\": 0.08}\n",
    "\n",
    "# Dictionary to store transpiled circuits\n",
    "circuits_transpiled = {}\n",
    "\n",
    "# Initialize total cost of the experiment\n",
    "cost = 0\n",
    "\n",
    "# Loop over different values of p (QAOA depth)\n",
    "for p in ps:\n",
    "    print(f\"---------  p: {p}  ----------\")\n",
    "\n",
    "    # Define parameter vectors for betas and gammas (QAOA variational parameters)\n",
    "    betas = ParameterVector(\"betas\", p)\n",
    "    gammas = ParameterVector(\"gammas\", p)\n",
    "\n",
    "    # Generate the QAOA quantum circuit for MaxCut\n",
    "    qc = qaoa_maxcut(G, gammas, betas)\n",
    "\n",
    "    # Create a new quantum circuit with the appropriate number of qubits and classical bits\n",
    "    circ = QuantumCircuit(max_qubits, reps * nq)\n",
    "\n",
    "    # Track the qubits used in the circuit\n",
    "    total_qubits_used = []\n",
    "\n",
    "    # Repeat the circuit for each section\n",
    "    for i in range(reps):\n",
    "        # Select qubits to be used for this section\n",
    "        qubits_used = qubits_device[nq * i + i: nq * (i + 1) + i]\n",
    "        # Alternative selection method:\n",
    "        # qubits_used = qubits_device[nq*i: nq*(i+1)]\n",
    "        \n",
    "        # Compose the circuit by adding the QAOA ansatz\n",
    "        circ = circ.compose(qc, qubits_used)\n",
    "\n",
    "        # Keep track of all qubits used\n",
    "        total_qubits_used += qubits_used\n",
    "\n",
    "    # Transpile the circuit for execution on the backend, optimizing it\n",
    "    circ_device = transpile(circ, optimization_level=3, basis_gates=[\"rxx\", \"h\", \"rx\", \"rz\"])\n",
    "\n",
    "    # Measure all used qubits and store results in classical bits (in reversed order)\n",
    "    circ_device.measure(total_qubits_used, reversed(range(reps * nq)))\n",
    "\n",
    "    # Store the transpiled circuit\n",
    "    circuits_transpiled[p] = circ_device\n",
    "\n",
    "    # Update the total cost of running the circuit\n",
    "    cost += results[\"shots\"] * shot_cost[backend_name] + 0.3\n",
    "\n",
    "# Print the estimated cost of the experiment\n",
    "print(f\"Cost of the run {cost}!!!\")\n",
    "\n",
    "# Store the total qubits used in the results dictionary\n",
    "results[\"total_qubits_used\"] = total_qubits_used\n",
    "\n",
    "# List to store circuits with assigned parameters\n",
    "circuits = []\n",
    "\n",
    "# Loop over different delta values\n",
    "for delta in deltas:\n",
    "    print(f\"Delta: -------  {round(delta,2)} ----------- \")\n",
    "\n",
    "    # Loop over different QAOA depths (p)\n",
    "    for p in ps:\n",
    "        # Define beta and gamma parameter values\n",
    "        betas = list(np.arange(1, p + 1)[::-1] * delta / p)\n",
    "        gammas = list(np.arange(1, p + 1) * delta / p)\n",
    "\n",
    "        # Assign parameters to the transpiled circuit\n",
    "        backend_circ = circuits_transpiled[p].assign_parameters(np.concatenate((betas, gammas)))\n",
    "\n",
    "        # Print the number of operations in the final circuit\n",
    "        print(f\"Operations for p={p}: {backend_circ.count_ops()}\")\n",
    "\n",
    "        # Store the circuit\n",
    "        circuits.append(backend_circ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the batch of circuits to the selected backend for execution\n",
    "job = backends[backend_name].run(circuits, shots=results[\"shots\"])\n",
    "\n",
    "# Store the job ID(s) in the results dictionary\n",
    "# Some backends may return multiple job IDs separated by \";\", so we split them into a list\n",
    "results[\"id\"] = job.job_id().split(\";\")\n",
    "\n",
    "# Save the results dictionary to a file for later retrieval\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_name = \"ionq_forte\"  # Define the backend being used\n",
    "nq = 17  # Define the number of qubits in the problem\n",
    "\n",
    "# Load previously saved results from a NumPy file\n",
    "results = np.load(f\"./Data/{backend_name}/{nq}_FC.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Retrieve results for each quantum circuit submitted\n",
    "dict_results = [\n",
    "    AwsQuantumTask(arn=results[\"id\"][nn]).result().measurement_counts \n",
    "    for nn, p in enumerate(results[\"ps\"])\n",
    "]\n",
    "\n",
    "# Sort the bitstrings based on node indices in the graph\n",
    "sort_bitstrings = np.argsort(list(results[\"G\"].nodes()))\n",
    "\n",
    "# Process the samples by sorting bitstrings and organizing them in a structured dictionary\n",
    "results[\"samples\"] = {\n",
    "    delta: {\n",
    "        p: {\n",
    "            \"\".join(k[ii] for ii in sort_bitstrings): v  # Reordering bitstrings based on sorted indices\n",
    "            for k, v in dict_results[i + nd * len(results[\"ps\"])].items()\n",
    "        }\n",
    "        for i, p in enumerate(results[\"ps\"])\n",
    "    }\n",
    "    for nd, delta in enumerate(results[\"Deltas\"])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of nodes in the graph\n",
    "nq = results[\"G\"].number_of_nodes()\n",
    "nq_total = results[\"G\"].number_of_nodes()  # Total number of nodes\n",
    "sections = nq_total // nq  # Determine the number of sections\n",
    "\n",
    "# Initialize dictionaries for storing post-processing results\n",
    "postprocessing = {}\n",
    "postprocessing_mitig = {}\n",
    "\n",
    "# Iterate through the results to process and mitigate data\n",
    "for delta in results[\"samples\"]:\n",
    "    postprocessing[delta] = {}\n",
    "    postprocessing_mitig[delta] = {}\n",
    "    \n",
    "    for p in results[\"samples\"][delta]:  # Iterate over different values of p\n",
    "        print(f\"----------- p = {p} -------------\")\n",
    "        postprocessing[delta][p] = {}\n",
    "        postprocessing_mitig[delta][p] = {}\n",
    "\n",
    "        for sec in range(sections):  # Iterate over sections\n",
    "            samples_sec = defaultdict(int)\n",
    "\n",
    "            # Extract relevant samples for the section\n",
    "            for k, v in results[\"samples\"][delta][p].items():\n",
    "                samples_sec[k[sec * nq : (sec + 1) * nq]] += v  # Slice the bitstring corresponding to the section\n",
    "\n",
    "            # Compute the objective function for MaxCut problem\n",
    "            postprocessing[delta][p][sec] = objective_MaxCut(samples_sec, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "            # Apply mitigation techniques and compute new objective function\n",
    "            new_samples = mitigate(samples_sec, results[\"G\"], random=False)\n",
    "            postprocessing_mitig[delta][p][sec] = objective_MaxCut(new_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Store post-processing results in the dictionary\n",
    "results[\"postprocessing\"] = postprocessing\n",
    "results[\"postprocessing_mitig\"] = postprocessing_mitig\n",
    "\n",
    "# Generate random bitstrings for comparison\n",
    "rand_samples = random_samples(10_000, nq)\n",
    "\n",
    "# Compute the objective function for random samples\n",
    "results[\"random\"] = objective_MaxCut(rand_samples, results[\"G\"], results[\"optimal\"])\n",
    "results[\"random_mitig\"] = objective_MaxCut(mitigate(rand_samples, results[\"G\"], random=False), results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Save the results dictionary to a NumPy file for later use\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
