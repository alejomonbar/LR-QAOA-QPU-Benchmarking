{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "# from qiskit_ibm_provider import IBMProvider\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "from docplex.mp.model import Model\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Sampler\n",
    "service = QiskitRuntimeService()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = {}\n",
    "backends[\"ibm_marrakesh\"] = service.backend('ibm_marrakesh')\n",
    "backends[\"ibm_fez\"] = service.backend('ibm_fez')\n",
    "backends[\"ibm_torino\"] = service.backend('ibm_torino')\n",
    "backends[\"ibm_brisbane\"] = service.backend('ibm_brisbane')\n",
    "\n",
    "backends[\"mps\"] = service.backend(\"simulator_mps\")\n",
    "backends[\"qasm_simulator\"] = AerSimulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main 1D-Chain IBM QPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits_in_line = {}\n",
    "# Eagle device\n",
    "qubits_1D_Eagle = list(range(13,-1,-1)) + [14] + list(range(18,33)) + [36] + list(range(51,36,-1)) + [52] + list(range(56,71)) + [74] + list(range(89,74,-1)) + [90] + list(range(94,109)) + [112] + list(range(126,112,-1))\n",
    "\n",
    "for backend in backends.keys():\n",
    "    if backend[:3] == \"ibm\" and backend != \"ibm_torino\":\n",
    "        qubits_in_line[backend] = qubits_1D_Eagle\n",
    "\n",
    "# Heron device\n",
    "qubits_in_line[\"ibm_torino\"] = list(range(14,-1,-1)) + [15] + list(range(19,34)) + [37] + list(range(52,37,-1)) + [53] + list(range(57,72)) + [75] + list(range(90,75,-1)) + [91] + list(range(95,110)) + [113] + list(range(128,113,-1)) + [129]\n",
    "qubits_in_line[\"ibm_fez\"] = list(range(0,16)) + [19] + list(range(35,20,-1)) + [36] + list(range(41,56)) + [59] + list(range(75,60,-1)) + [76] + list(range(81,96)) + [99] + list(range(115,100,-1)) + [116] + list(range(121,136)) + [139] + list(range(155,139,-1))\n",
    "qubits_in_line[\"ibm_marrakesh\"] = list(range(0,16)) + [19] + list(range(35,20,-1)) + [36] + list(range(41,56)) + [59] + list(range(75,60,-1)) + [76] + list(range(81,96)) + [99] + list(range(115,100,-1)) + [116] + list(range(121,136)) + [139] + list(range(155,139,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAOA Circuit - SWAP network strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "import numpy as np\n",
    "\n",
    "def layer_1D_full_Graph(G, gamma):\n",
    "    \"\"\"\n",
    "    Constructs a single layer of the QAOA circuit for a 1D swap network.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The problem graph, where nodes represent qubits, \n",
    "                          and edges contain weights for interactions.\n",
    "    - gamma (float): The parameter controlling the evolution of the cost Hamiltonian.\n",
    "\n",
    "    Returns:\n",
    "    - layer (QuantumCircuit): A quantum circuit implementing the ZZ evolution with swaps.\n",
    "    \"\"\"\n",
    "    num_qubits = G.number_of_nodes()\n",
    "    \n",
    "    # Track current qubit permutation due to swaps\n",
    "    permutation = np.arange(num_qubits)\n",
    "    \n",
    "    # Normalize edge weights\n",
    "    max_weight = np.max(np.abs([G[i][j][\"weight\"] for i, j in G.edges()]))\n",
    "\n",
    "    # Initialize the quantum circuit for one layer\n",
    "    layer = QuantumCircuit(num_qubits)\n",
    "    \n",
    "    # Implement the swap network with RZZ gates\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(i % 2, num_qubits - 1, 2):\n",
    "            # Apply a controlled-X (CNOT) gate\n",
    "            layer.cx(j, j + 1)\n",
    "            \n",
    "            # Apply a weighted RZ rotation on the second qubit\n",
    "            layer.rz(2 * G[permutation[j]][permutation[j + 1]][\"weight\"] * gamma / max_weight, j + 1)\n",
    "            \n",
    "            # Undo the CX gate sequence to restore original states\n",
    "            layer.cx(j + 1, j)\n",
    "            layer.cx(j, j + 1)\n",
    "            \n",
    "            # Update the permutation due to the swap\n",
    "            permutation[[j, j + 1]] = permutation[[j + 1, j]]\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def qaoa_swap_network(G, gammas, betas):\n",
    "    \"\"\"\n",
    "    Constructs a full QAOA circuit using a swap network for a 1D architecture.\n",
    "\n",
    "    This is useful for fully connected problems (e.g., complete graphs) where\n",
    "    all qubits need pairwise interactions.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The problem graph with weighted edges.\n",
    "    - gammas (list of floats): The QAOA parameters for cost Hamiltonian evolution.\n",
    "    - betas (list of floats): The QAOA parameters for mixer Hamiltonian evolution.\n",
    "\n",
    "    Returns:\n",
    "    - circ (QuantumCircuit): The full QAOA quantum circuit.\n",
    "    \"\"\"\n",
    "    num_qubits = G.number_of_nodes()\n",
    "    p = len(gammas)  # Number of QAOA layers\n",
    "\n",
    "    # Initialize the QAOA quantum circuit\n",
    "    circ = QuantumCircuit(num_qubits)\n",
    "\n",
    "    # Apply the initial layer of Hadamard gates to all qubits\n",
    "    for i in range(num_qubits):\n",
    "        circ.h(i)\n",
    "    # Function to generate each layer\n",
    "    layer = lambda gamma: layer_1D_full_Graph(G, gamma)\n",
    "\n",
    "    # Add p layers of QAOA\n",
    "    for pi in range(p):\n",
    "        # Apply the cost Hamiltonian evolution (ZZ interactions with swaps)\n",
    "        circ = circ.compose(layer(gammas[pi]), \n",
    "                            range(num_qubits) if not pi % 2 else reversed(range(num_qubits)))\n",
    "        # Apply the mixer Hamiltonian evolution (RX rotations)\n",
    "        circ.rx(-2 * betas[pi], range(num_qubits))    \n",
    "    return circ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_maxcut(bitstring, weights):\n",
    "    \"\"\"\n",
    "    Computes the cost of a given bitstring solution for the Max-Cut problem.\n",
    "\n",
    "    Parameters:\n",
    "    bitstring (str): A binary string representing a partition of the graph nodes (e.g., \"1010\").\n",
    "    weights (dict): A dictionary where keys are edge tuples (i, j) and values are edge weights.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed cost of the Max-Cut solution.\n",
    "    \"\"\"\n",
    "    cost = 0  # Initialize the cost\n",
    "    \n",
    "    # Iterate through all edges in the graph\n",
    "    for i, j in weights.keys():\n",
    "        # Check if the nodes i and j are in different partitions (cut condition)\n",
    "        if bitstring[i] + bitstring[j] in [\"10\", \"01\"]:\n",
    "            cost += weights[i, j]  # Add the edge weight to the cost\n",
    "\n",
    "    return cost  # Return the total cut cost\n",
    "\n",
    "\n",
    "def objective_MaxCut(samples_dict, G, optimal):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a quantum algorithm for the Max-Cut problem.\n",
    "\n",
    "    Parameters:\n",
    "    samples_dict (dict): A dictionary where keys are bitstrings (binary solutions), \n",
    "                         and values are their occurrence counts.\n",
    "    G (networkx.Graph): The input weighted graph where edges represent cut costs.\n",
    "    optimal (str): The optimal bitstring solution found by classical solvers (e.g., CPLEX).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing:\n",
    "        - \"results\": A numpy array with computed cost, normalized cost ratio, and counts.\n",
    "        - \"G\": The input graph G.\n",
    "        - \"weights\": The edge weights extracted from G.\n",
    "        - \"max_cut\": The cost of the optimal Max-Cut solution.\n",
    "        - \"r\": The expected approximation ratio.\n",
    "        - \"probability\": The probability of sampling the optimal solution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract weights from the graph's edges\n",
    "    weights = {(i, j): (G[i][j][\"weight\"] if len(G[i][j]) != 0 else 1) for i, j in G.edges}\n",
    "    \n",
    "    # Compute the cost of the optimal Max-Cut solution\n",
    "    max_cost = cost_maxcut(optimal, weights)\n",
    "\n",
    "    results = []  # Stores results in the form [cost, ratio, counts]\n",
    "    probability = 0  # Tracks probability of sampling the optimal solution\n",
    "\n",
    "    # Iterate through all sampled bitstrings\n",
    "    for bitstring, counts in samples_dict.items():\n",
    "        cost = cost_maxcut(bitstring, weights)  # Compute cost of the given bitstring\n",
    "        r = cost / max_cost  # Compute the cost ratio relative to the optimal solution\n",
    "        results.append([cost, r, counts])  # Store results\n",
    "        \n",
    "        # If this bitstring matches the optimal cost, update probability\n",
    "        if abs(cost - max_cost) < 1e-6:\n",
    "            probability += counts\n",
    "        \n",
    "        # Check if a better-than-optimal solution appears (sanity check)\n",
    "        if cost > max_cost:\n",
    "            print(f\"There is a better cost than that of CPLEX: {cost - max_cost}\")\n",
    "\n",
    "    # Convert results to a NumPy array for easy computation\n",
    "    results = np.array(results)\n",
    "\n",
    "    # Total number of shots (total sampled solutions)\n",
    "    shots = np.sum(results[:, 2])\n",
    "\n",
    "    # Compute the expected approximation ratio: (weighted sum of costs) / (shots * max_cost)\n",
    "    rT = np.sum(results[:, 0] * results[:, 2]) / (shots * max_cost)\n",
    "\n",
    "    # Normalize the probability of sampling the optimal solution\n",
    "    probability /= shots\n",
    "\n",
    "    # Return results in a structured dictionary\n",
    "    return {\n",
    "        \"results\": np.array(results),\n",
    "        \"G\": G,\n",
    "        \"weights\": weights,\n",
    "        \"max_cut\": max_cost,\n",
    "        \"r\": rT,\n",
    "        \"probability\": probability\n",
    "    }\n",
    "\n",
    "def mitigate(samples_dict, G, random=False):\n",
    "    \"\"\"\n",
    "    Applies error mitigation by flipping individual bits in sampled solutions \n",
    "    to find better Max-Cut solutions.\n",
    "\n",
    "    Parameters:\n",
    "    samples_dict (dict): A dictionary where keys are bitstrings (binary solutions), \n",
    "                         and values are their occurrence counts.\n",
    "    G (networkx.Graph): The input weighted graph where edges represent cut costs.\n",
    "    random (bool, optional): If True, randomizes the order in which qubits are flipped.\n",
    "                             Default is False (systematic flipping).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of improved bitstring samples with their updated counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a mapping to flip bits ('0' -> '1', '1' -> '0')\n",
    "    change = {\"0\": \"1\", \"1\": \"0\"}\n",
    "\n",
    "    # Get the number of nodes (qubits)\n",
    "    nq = G.number_of_nodes()\n",
    "\n",
    "    # Extract weights from the graph's edges\n",
    "    weights = {(i, j): (G[i][j][\"weight\"] if len(G[i][j]) != 0 else 1) for i, j in G.edges}\n",
    "\n",
    "    # Dictionary to store new (improved) samples\n",
    "    new_samples = defaultdict(int)\n",
    "\n",
    "    # Iterate over all bitstring samples\n",
    "    for bitstring, counts in samples_dict.items():\n",
    "        for _ in range(counts):  # Process each occurrence of the bitstring separately\n",
    "            best_string = bitstring  # Initialize the best solution as the current one\n",
    "            best_cost = cost_maxcut(bitstring, weights)  # Compute its cost\n",
    "            \n",
    "            # Create an ordered list of qubits (nodes) to consider flipping\n",
    "            list_qubits = np.arange(nq)\n",
    "            \n",
    "            # If random flipping is enabled, shuffle the qubit order\n",
    "            if random:\n",
    "                np.random.shuffle(list_qubits)\n",
    "\n",
    "            # Try flipping each qubit and check if the cost improves\n",
    "            for qi in list_qubits:\n",
    "                # Flip the bit at position qi\n",
    "                new_string = \"\".join((change[i] if n == qi else i) for n, i in enumerate(best_string))\n",
    "                new_cost = cost_maxcut(new_string, weights)\n",
    "\n",
    "                # If the new configuration gives a better cost, update the best solution\n",
    "                if new_cost > best_cost:\n",
    "                    best_string = new_string\n",
    "                    best_cost = new_cost\n",
    "            \n",
    "            # Store the improved bitstring in the new_samples dictionary\n",
    "            new_samples[best_string] += 1\n",
    "\n",
    "    return new_samples  # Return the mitigated samples\n",
    "\n",
    "def random_samples(num_samples, n_qubits):\n",
    "    \"\"\"\n",
    "    Generates random bitstring samples for a given number of qubits.\n",
    "\n",
    "    Parameters:\n",
    "    num_samples (int): The number of random bitstrings to generate.\n",
    "    n_qubits (int): The number of qubits (length of each bitstring).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are randomly generated bitstrings \n",
    "          and values are their occurrence counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    random_samples = defaultdict(int)  # Dictionary to store bitstrings and their counts\n",
    "\n",
    "    # Generate random bitstrings and count their occurrences\n",
    "    for _ in range(num_samples):\n",
    "        bitstring = \"\".join(str(i) for i in np.random.choice([0, 1], n_qubits))  # Generate a random bitstring\n",
    "        random_samples[bitstring] += 1  # Increment count for the generated bitstring\n",
    "\n",
    "    return random_samples  # Return the dictionary of samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = np.load(\"./Data/WMC_FC.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  p: 3  ----------\n",
      "---------  p: 4  ----------\n",
      "---------  p: 5  ----------\n",
      "---------  p: 6  ----------\n",
      "---------  p: 7  ----------\n",
      "---------  p: 8  ----------\n",
      "---------  p: 9  ----------\n",
      "---------  p: 10  ----------\n",
      "---------  p: 13  ----------\n",
      "---------  p: 15  ----------\n",
      "---------  p: 20  ----------\n",
      "Delta: -------  0.63 ----------- \n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Define the backend for quantum computation (uncomment the desired backend)\n",
    "# backend_name = \"ibm_brisbane\"\n",
    "# backend_name = \"ibm_sherbrooke\"\n",
    "# backend_name = \"ibm_kyiv\"\n",
    "# backend_name = \"ibm_nazca\"\n",
    "# backend_name = \"ibm_osaka\"\n",
    "# backend_name = \"ibm_kyoto\"\n",
    "# backend_name = \"ibm_torino\"\n",
    "# backend_name = \"ibm_fez\"\n",
    "backend_name = \"ibm_marrakesh\"  # Selected backend\n",
    "# backend_name = \"qasm_simulator\"  # Uncomment to use a classical simulator\n",
    "\n",
    "# Get the backend from the available backends dictionary\n",
    "backend = backends[backend_name]\n",
    "\n",
    "# Number of qubits used in the problem\n",
    "nq = 20\n",
    "\n",
    "# Define qubit mapping for the QASM simulator\n",
    "qubits_in_line[\"qasm_simulator\"] = range(nq)\n",
    "\n",
    "# Define delta values for parameter tuning in QAOA (uncomment as needed)\n",
    "# deltas = [0.05, 0.1, 0.2, 0.3, 0.5, 0.63] # For 50 qubits\n",
    "# deltas = np.linspace(0.4, 1, 10)  # Generates evenly spaced deltas\n",
    "# deltas = [0.3]  # Alternative single delta value\n",
    "deltas = [0.63]  # Chosen delta for this experiment\n",
    "\n",
    "# Store delta values in results\n",
    "results[\"Deltas\"] = deltas\n",
    "\n",
    "# Load the problem graph for the given number of qubits\n",
    "G = problems[nq][\"G\"]\n",
    "results[\"G\"] = G  # Store the graph in results\n",
    "\n",
    "# Get the device-specific qubit layout\n",
    "qubits_device = qubits_in_line[backend_name] \n",
    "\n",
    "# Calculate the number of sections (repetitions) based on available qubits\n",
    "reps = len(qubits_device) // (nq + 1) if backend_name != \"qasm_simulator\" else 1\n",
    "results[\"sections\"] = reps  # Store the number of sections\n",
    "\n",
    "# Determine the maximum number of qubits available in the backend\n",
    "max_qubits = backend.num_qubits if backend_name != \"qasm_simulator\" else nq\n",
    "\n",
    "# Define the number of QAOA layers (ps values) to test\n",
    "# ps = [0, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25, 30, 40, 50]  # Alternative set\n",
    "ps = [3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20]  # Selected set of layers\n",
    "# ps = [3, 5, 10, 20]  # Alternative smaller set\n",
    "# ps = [20]  # Single depth experiment\n",
    "\n",
    "# Store layer values and optimal solution in results\n",
    "results[\"ps\"] = ps\n",
    "results[\"optimal\"] = problems[nq][\"sol\"]\n",
    "\n",
    "# Dictionary to store transpiled circuits\n",
    "circuits_transpiled = {}\n",
    "\n",
    "# Loop through different values of p (QAOA layers)\n",
    "for p in ps:\n",
    "    print(f\"---------  p: {p}  ----------\")  # Print progress\n",
    "\n",
    "    # Define QAOA parameters as symbolic variables\n",
    "    betas = ParameterVector(\"betas\", p)\n",
    "    gammas = ParameterVector(\"gammas\", p)\n",
    "\n",
    "    # Create the QAOA circuit using a swap network approach\n",
    "    qc = qaoa_swap_network(G, gammas, betas)\n",
    "\n",
    "    # Initialize a quantum circuit matching the backend qubit count\n",
    "    circ = QuantumCircuit(max_qubits, reps * nq)\n",
    "\n",
    "    # Track qubits used in the circuit\n",
    "    total_qubits_used = []\n",
    "\n",
    "    # Embed the circuit into the available hardware qubits\n",
    "    for i in range(reps):\n",
    "        qubits_used = qubits_device[nq * i + i : nq * (i + 1) + i]\n",
    "        # Alternative qubit assignment:\n",
    "        # qubits_used = qubits_device[nq*i: nq*(i+1)]\n",
    "\n",
    "        # Attach the QAOA circuit to the selected qubits\n",
    "        circ = circ.compose(qc, qubits_used)\n",
    "\n",
    "        # Store the qubits used\n",
    "        total_qubits_used += qubits_used\n",
    "\n",
    "    # Transpile the circuit for the target backend (no optimization applied)\n",
    "    circ_device = transpile(circ, backend, optimization_level=0, initial_layout=range(max_qubits))\n",
    "\n",
    "    # Add measurement operations to the circuit\n",
    "    circ_device.measure(total_qubits_used, reversed(range(reps * nq)) if not p % 2 else range(nq * reps))\n",
    "\n",
    "    # Store the transpiled circuit\n",
    "    circuits_transpiled[p] = circ_device\n",
    "\n",
    "# Store the total qubits used in the results\n",
    "results[\"total_qubits_used\"] = total_qubits_used\n",
    "\n",
    "# List to store final circuits with assigned parameters\n",
    "circuits = []\n",
    "\n",
    "# Iterate over different delta values\n",
    "for delta in deltas:\n",
    "    print(f\"Delta: -------  {round(delta, 2)} ----------- \")\n",
    "\n",
    "    # Iterate over different QAOA depths (p values)\n",
    "    for p in ps:\n",
    "        # Compute the betas and gammas based on the delta value\n",
    "        betas = list(np.arange(1, p + 1)[::-1] * delta / p)\n",
    "        gammas = list(np.arange(1, p + 1) * delta / p)\n",
    "\n",
    "        # Assign the computed parameters to the transpiled circuit\n",
    "        backend_circ = circuits_transpiled[p].assign_parameters(np.concatenate((betas, gammas)))\n",
    "\n",
    "        # Store the final circuit\n",
    "        circuits.append(backend_circ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/d4kyjysx1xgdrrs6zzs63s180000gn/T/ipykernel_88515/3126640788.py:3: DeprecationWarning: backend.run() and related sessions methods are deprecated  as of qiskit-ibm-runtime 0.23 and will be removed no sooner than 6 months after the release date. More details can be found in the primitives migration guide https://docs.quantum.ibm.com/migration-guides/qiskit-runtime.\n",
      "  submit_job = backends[backend_name].run(circuits, shots=shots)\n"
     ]
    }
   ],
   "source": [
    "# Define the number of shots (number of times the quantum circuit is executed)\n",
    "shots = 1000\n",
    "\n",
    "# Check if the selected backend is NOT the QASM simulator (i.e., using real quantum hardware)\n",
    "if backend_name != \"qasm_simulator\":\n",
    "    # Submit the quantum job to the selected IBMQ backend\n",
    "    submit_job = backends[backend_name].run(circuits, shots=shots)\n",
    "\n",
    "    # Store the job ID in results to track and retrieve it later\n",
    "    results[\"id\"] = submit_job.job_id()  \n",
    "else:\n",
    "    # If using the QASM simulator, execute the circuits locally and get the results immediately\n",
    "    dict_results = backends[backend_name].run(circuits, shots=shots).result().get_counts()\n",
    "\n",
    "    # Store the results in a structured dictionary format\n",
    "    # The results dictionary is indexed first by delta, then by QAOA depth (p), \n",
    "    # and finally by the measurement outcomes (bitstrings) with their corresponding counts.\n",
    "    results[\"samples\"] = {\n",
    "        delta: {\n",
    "            p: {k: v for k, v in dict_results[i + nd * len(ps)].items()}\n",
    "            for i, p in enumerate(results[\"ps\"])\n",
    "        }\n",
    "        for nd, delta in enumerate(results[\"Deltas\"])\n",
    "    }\n",
    "\n",
    "# Save the results dictionary as a NumPy binary file for future use\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve QPU experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the backend name (IBM quantum processor being used)\n",
    "backend_name = \"ibm_marrakesh\"\n",
    "\n",
    "# Define the number of qubits used in the computation\n",
    "nq = 20\n",
    "\n",
    "# Load previously saved results from a NumPy binary file\n",
    "results = np.load(f\"./Data/{backend_name}/{nq}_FC.npy\", allow_pickle=True).item()\n",
    "\n",
    "# If running on real quantum hardware (not a simulator)\n",
    "if backend_name != \"qasm_simulator\":\n",
    "    # Retrieve the job results from IBM's quantum service using the stored job ID\n",
    "    jobs = service.job(job_id=results[\"id\"]).result()\n",
    "\n",
    "    # Extract the measurement counts (bitstring results) from the job results\n",
    "    dict_results = jobs.get_counts()\n",
    "\n",
    "    # Store the results in a structured dictionary format\n",
    "    # - Organized by delta values and QAOA depth (p)\n",
    "    # - The bitstrings (measurement outcomes) are mapped to their corresponding counts\n",
    "    results[\"samples\"] = {\n",
    "        delta: {\n",
    "            p: {k: v for k, v in dict_results[i + nd * len(ps)].items()}\n",
    "            for i, p in enumerate(results[\"ps\"])\n",
    "        }\n",
    "        for nd, delta in enumerate(results[\"Deltas\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- p = 3 -------------\n",
      "----------- p = 4 -------------\n",
      "----------- p = 5 -------------\n",
      "----------- p = 6 -------------\n",
      "----------- p = 7 -------------\n",
      "----------- p = 8 -------------\n",
      "----------- p = 9 -------------\n",
      "----------- p = 10 -------------\n",
      "----------- p = 13 -------------\n",
      "----------- p = 15 -------------\n",
      "----------- p = 20 -------------\n"
     ]
    }
   ],
   "source": [
    "# Get the number of nodes (qubits) in the graph problem\n",
    "nq = results[\"G\"].number_of_nodes()\n",
    "\n",
    "# Get the number of sections (used for processing multiple groups of qubits in a single execution)\n",
    "sections = results[\"sections\"]\n",
    "\n",
    "# Initialize dictionaries to store postprocessing results\n",
    "postprocessing = {}\n",
    "postprocessing_mitig = {}\n",
    "\n",
    "# Iterate over different delta values (used for QAOA parameter tuning)\n",
    "for delta in results[\"samples\"]:\n",
    "    postprocessing[delta] = {}\n",
    "    postprocessing_mitig[delta] = {}\n",
    "\n",
    "    # Iterate over different QAOA depths (p values)\n",
    "    for p in results[\"samples\"][delta]:\n",
    "        print(f\"----------- p = {p} -------------\")\n",
    "        postprocessing[delta][p] = {}\n",
    "        postprocessing_mitig[delta][p] = {}\n",
    "\n",
    "        # Iterate over different sections (to handle multiple independent executions within a job)\n",
    "        for sec in range(sections):\n",
    "            samples_sec = defaultdict(int)\n",
    "\n",
    "            # Extract relevant bitstring samples for the current section\n",
    "            for k, v in results[\"samples\"][delta][p].items():\n",
    "                samples_sec[k[sec*nq:(sec+1)*nq]] += v\n",
    "\n",
    "            # Compute the MaxCut objective for the extracted samples\n",
    "            postprocessing[delta][p][sec] = objective_MaxCut(samples_sec, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "            # Apply error mitigation to the samples\n",
    "            new_samples = mitigate(samples_sec, results[\"G\"], random=False)\n",
    "\n",
    "            # Compute the MaxCut objective after error mitigation\n",
    "            postprocessing_mitig[delta][p][sec] = objective_MaxCut(new_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Store the postprocessing results\n",
    "results[\"postprocessing\"] = postprocessing\n",
    "results[\"postprocessing_mitig\"] = postprocessing_mitig\n",
    "\n",
    "# Generate random bitstring samples for comparison (10,000 random samples)\n",
    "rand_samples = random_samples(10_000, nq)\n",
    "\n",
    "# Compute MaxCut objective for the random samples\n",
    "results[\"random\"] = objective_MaxCut(rand_samples, results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Apply error mitigation to the random samples and compute MaxCut objective\n",
    "results[\"random_mitig\"] = objective_MaxCut(mitigate(rand_samples, results[\"G\"], random=False), results[\"G\"], results[\"optimal\"])\n",
    "\n",
    "# Save the updated results back to a NumPy binary file\n",
    "np.save(f\"./Data/{backend_name}/{nq}_FC.npy\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
